{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "tree = pd.read_csv('tree.csv')\n",
    "tree['t'] = tree['t'].replace(to_replace=0, value=0.1)\n",
    "\n",
    "vert_genes = pd.read_csv('vert_genes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the graph\n",
    "\n",
    "def create_graph(tree, alpha, beta, sigma_sq):\n",
    "    G = nx.DiGraph()\n",
    "    for _, row in tree.iterrows():\n",
    "        if not pd.isna(row['Parent']):\n",
    "            G.add_edge(int(row[\"Parent\"]), int(row[\"Child\"]), time = row[\"t\"], a = alpha*row[\"t\"], b = beta, variance = sigma_sq*row[\"t\"])\n",
    "            \n",
    "    return G\n",
    "\n",
    "G = create_graph(tree, alpha = 0, beta = 1, sigma_sq = 2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_node_length_with_parameters(G, parent, simulated_lengths, alpha, beta, sigma_sq):\n",
    "    for child in G.successors(parent):\n",
    "        t = G[parent][child]['time']\n",
    "        mean = alpha * t + beta * simulated_lengths[parent]\n",
    "        std = np.sqrt(sigma_sq * t)\n",
    "        simulated_lengths[child] = np.random.normal(mean, std)\n",
    "        simulate_node_length_with_parameters(G, child, simulated_lengths, alpha, beta, sigma_sq)\n",
    "    \n",
    "    return simulated_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 204)\n",
      "(1000,)\n",
      "50116.03336955078\n"
     ]
    }
   ],
   "source": [
    "def simulate_data_for_learning(G, n, alpha, beta, sigma_sq, alpha_0, sigma_0_sq, root, learn_params = True, only_X = True):\n",
    "    X_values = []\n",
    "    Y_values = []\n",
    "    \n",
    "    all_nodes = list(G.nodes)  # Get all nodes in the graph\n",
    "\n",
    "    for _ in range(n):\n",
    "        simulated_lengths = {}\n",
    "        \n",
    "        # Simulate root node first\n",
    "        simulated_lengths[root] = np.random.normal(alpha_0, np.sqrt(sigma_0_sq))\n",
    "        \n",
    "        # Simulate all other nodes recursively\n",
    "        simulated_lengths = simulate_node_length_with_parameters(G, root, simulated_lengths, alpha, beta, sigma_sq)\n",
    "        if only_X:\n",
    "            leaf_nodes = [node for node in all_nodes if G.out_degree(node) == 0]\n",
    "            simulated_x = [simulated_lengths[node] for node in leaf_nodes]\n",
    "            \n",
    "            X_values.append(simulated_x)\n",
    "        else:\n",
    "            X_values.append([simulated_lengths[node] for node in all_nodes])\n",
    "            \n",
    "        if learn_params:\n",
    "            Y_values.append([alpha,beta,sigma_sq])\n",
    "        else:\n",
    "            Y_values.append(simulated_lengths[root])\n",
    "\n",
    "    return np.array(X_values), np.array(Y_values)\n",
    "\n",
    "learn_parameters = False\n",
    "\n",
    "X, y = simulate_data_for_learning(G, 1000, alpha = 0.5, beta = 1, sigma_sq = 2500, alpha_0 = 50000, sigma_0_sq = 5000, root = 407, learn_params=learn_parameters)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "print(y[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gamma(G):\n",
    "    gamma = np.eye(len(G.nodes)) # Initialize gamma as an identity matrix\n",
    "\n",
    "    # Iterate through the nodes in the graph\n",
    "    for node in G.nodes:\n",
    "        parent = next(G.predecessors(node), None)\n",
    "        if parent is None:\n",
    "            print(f\"Node {node} is the root node.\")\n",
    "            continue\n",
    "        else:\n",
    "            gamma[parent-1, node -1] = -G[parent][node]['b'] # Determine the dependency between parent and child nodes with -b\n",
    "    return gamma\n",
    "\n",
    "def compute_beta(G, alpha_0 = 50000):\n",
    "    beta = np.zeros((len(G.nodes), 1))\n",
    "    for node in G.nodes:\n",
    "        parent = next(G.predecessors(node), None)\n",
    "        if parent is None:\n",
    "            beta[node-1] = alpha_0\n",
    "            continue\n",
    "        a = G[parent][node]['a'] # The constant term in the mean of the CPD\n",
    "        beta[node-1] = a\n",
    "        \n",
    "    return beta\n",
    "\n",
    "def compute_sigma(G, sigma_0_sq = 5000):\n",
    "    sigma = np.zeros((len(G.nodes)))\n",
    "    for node in G.nodes:\n",
    "        parent = next(G.predecessors(node), None)\n",
    "        if parent is None:\n",
    "            # Assign the default value for the root node\n",
    "            sigma[node - 1] = sigma_0_sq\n",
    "        else:\n",
    "            # Access the edge attribute 'variance' only if parent exists\n",
    "            variance = G[parent][node]['variance']\n",
    "            sigma[node - 1] = variance\n",
    "    return sigma\n",
    "\n",
    "def compute_J_and_h(alpha, beta, sigma_sq, sigma_0_sq = 5000):\n",
    "    \n",
    "    G = create_graph(tree, alpha, beta, sigma_sq)\n",
    "\n",
    "    beta = compute_beta(G)\n",
    "    sigma = compute_sigma(G, sigma_0_sq)\n",
    "    gamma = compute_gamma(G)\n",
    "\n",
    "    J = np.sum([np.outer(gamma[:, i], gamma[:, i]) / sigma[i] for i in range(len(G))], axis=0)\n",
    "    h = np.sum([(beta[i] / sigma[i]) * gamma[:, i] for i in range(len(G))], axis=0)\n",
    "    return J, h\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 407 is the root node.\n",
      "(407, 407) (407, 407)\n",
      "Difference between empirical and computed covariance matrix \n",
      ": [[-16172.60401878   7030.76357501  12715.03642319 ...   2754.72991758\n",
      "   -4430.01376399  -4293.49016197]\n",
      " [  7030.76357501   8596.70031247  13402.82485447 ...    484.37635554\n",
      "   -5751.14212241  -5740.2847144 ]\n",
      " [ 12715.03642319  13402.82485447   3545.71424905 ...   2265.97528042\n",
      "   -4929.83142472  -4766.43414795]\n",
      " ...\n",
      " [  2754.72991758    484.37635554   2265.97528042 ... -15951.53991818\n",
      "  -97424.79962474   7824.05624074]\n",
      " [ -4430.01376399  -5751.14212241  -4929.83142472 ... -97424.79962474\n",
      "  -20532.44165264  92312.20650686]\n",
      " [ -4293.49016197  -5740.2847144   -4766.43414795 ...   7824.05624074\n",
      "   92312.20650686  96580.76976067]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0., 10.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 1000\n",
    "\n",
    "alpha = 0\n",
    "beta = 1\n",
    "sigma_sq = 2500\n",
    "All_nodes_simulated, _ = simulate_data_for_learning(G, n, alpha=alpha, beta=beta, sigma_sq=sigma_sq, alpha_0=50000, sigma_0_sq=5000, root=407, learn_params=False, only_X=False)\n",
    "empirical_covariance_matrix = np.cov(All_nodes_simulated, rowvar=False)\n",
    "\n",
    "J, h = compute_J_and_h(alpha = alpha, beta = beta, sigma_sq = sigma_sq)\n",
    "\n",
    "computed_covariance_matrix = np.linalg.inv(J)\n",
    "\n",
    "print(empirical_covariance_matrix.shape, computed_covariance_matrix.shape)\n",
    "\n",
    "\n",
    "difference =  empirical_covariance_matrix - computed_covariance_matrix\n",
    "print(f\"Difference between empirical and computed covariance matrix \\n: {difference}\")\n",
    "\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_clique_tree(G):\n",
    "    C = nx.Graph()\n",
    "\n",
    "    G_working = G.copy()\n",
    "    leaves = [node for node in G_working.nodes if G_working.out_degree(node) == 0]\n",
    "    G_working.remove_nodes_from(leaves)\n",
    "\n",
    "    index = min(G_working.nodes) -1 if all(isinstance(n, int) for n in G_working.nodes) else 0\n",
    "\n",
    "    for node in G_working.nodes:\n",
    "        parent = node\n",
    "        children = list(G_working.neighbors(parent))\n",
    "        C.add_node(parent, variables=[parent])\n",
    "        for child in children:\n",
    "            pair_clique = index\n",
    "            C.add_node(pair_clique, variables=[parent, child])\n",
    "            C.add_edge(parent, pair_clique)\n",
    "            C.add_edge(pair_clique, child)\n",
    "            index = index - 1\n",
    "\n",
    "    return C\n",
    "\n",
    "C = compute_clique_tree(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Away from zero:  205\n",
      "Max index:  407\n",
      "Min index:  205\n",
      "Number of variables in the graph:  202\n"
     ]
    }
   ],
   "source": [
    "NoV = len([node for node in C.nodes if len(C.nodes[node]['variables']) == 1]) -1\n",
    "maxIndex = max([node for node in C.nodes])\n",
    "away_from_zero = maxIndex - NoV\n",
    "minIndex = min([node for node in C.nodes if len(C.nodes[node]['variables']) == 1])\n",
    "\n",
    "print(\"Away from zero: \", away_from_zero)\n",
    "print(\"Max index: \", maxIndex)\n",
    "print(\"Min index: \", minIndex)\n",
    "print(\"Number of variables in the graph: \", NoV)\n",
    "\n",
    "def mapping_GTM(index_in_graph):\n",
    "    return index_in_graph - away_from_zero \n",
    "\n",
    "def mapping_MTG(index_in_matrix):\n",
    "    return index_in_matrix + away_from_zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix algebra implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub_matrices(scope, X_values, J, h):\n",
    "    X_indices = np.isin(scope, X_values)\n",
    "    Z_indices = ~X_indices\n",
    "\n",
    "    J_ZZ = J[Z_indices, :][:, Z_indices]\n",
    "    J_ZX = J[Z_indices, :][:, X_indices]\n",
    "    J_XZ = J_ZX.T\n",
    "    J_XX = J[X_indices, :][:, X_indices]\n",
    "    J_ZZ_inv = np.linalg.inv(J_ZZ)\n",
    "\n",
    "    h_X = h[X_indices]\n",
    "    h_Z = h[Z_indices]\n",
    "\n",
    "    return J_ZZ, J_ZX, J_XZ, J_XX, J_ZZ_inv, h_X, h_Z\n",
    "\n",
    "def get_conditional_distribution(J, h, X_values, X_indices):\n",
    "    scope = [i for i in range(1, len(J) + 1)]\n",
    "    J_ZZ, J_ZX, J_XZ, J_XX, J_ZZ_inv, h_X, h_Z = get_sub_matrices(scope, X_indices, J, h)\n",
    "\n",
    "    J_reduced = J_ZZ\n",
    "    h_reduced = h_Z- J_ZX @ X_values\n",
    "\n",
    "    return J_reduced, h_reduced\n",
    "\n",
    "X_values = simulate_data_for_learning(G, 1, alpha=alpha, beta=beta, sigma_sq=sigma_sq, alpha_0=50000, sigma_0_sq=5000, root=407, learn_params=False, only_X=True)[0]\n",
    "\n",
    "\n",
    "leaves = [node for node in G.nodes if G.out_degree(node) == 0]\n",
    "X_indices = leaves\n",
    "\n",
    "J_reduced, h_reduced = get_conditional_distribution(J, h, X_values[0], X_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value for node 407: 49885.98983680517\n",
      "Variance for node 407: 15906.197622746702\n",
      "Actual value for node 407: 49881.28480624464\n",
      "True variance for node 407: 2500\n"
     ]
    }
   ],
   "source": [
    "Sigma = np.linalg.inv(J_reduced)\n",
    "mu = Sigma @ h_reduced\n",
    "\n",
    "random_index = np.random.choice(range(len(X_values[0])))\n",
    "z = mapping_GTM(random_index)\n",
    "print(f\"Predicted value for node 407: {mu[z]}\")\n",
    "print(f\"Variance for node 407: {Sigma[z,z]}\")\n",
    "print(f\"Actual value for node 407: {X_values[0][0]}\")\n",
    "print(f\"True variance for node 407: {sigma_sq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II : inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in clique tree: 203\n",
      "J_hat_Z: 0.00028940114546818524\n",
      "h_hat_Z: 14.62022314623666\n",
      "True mean: 50616.455617331274\n",
      "True std dev: 2500\n",
      "Posterior mean: 50518.884859921556\n",
      "Posterior std dev: 58.78274696273216\n",
      "Total messages sent: [3350, 55]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_18584\\652121175.py:20: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  J_sum = np.sum(compute_J_i_arrow_j(clique_tree, k, i, J, h, J_messages, h_messages, globalcounter) for k in neighbors)\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_18584\\652121175.py:39: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  J_sum = np.sum(compute_J_i_arrow_j(clique_tree, k, i, J, h, J_messages, h_messages, globalcounter) for k in neighbors)\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_18584\\652121175.py:40: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  h_sum = np.sum(compute_h_i_arrow_j(clique_tree, k, i, J, h, J_messages, h_messages, globalcounter) for k in neighbors)\n"
     ]
    }
   ],
   "source": [
    "def single_clique(G):\n",
    "    leaves = [node for node in G.nodes if G.out_degree(node) == 0]\n",
    "    H = G.copy()\n",
    "    H.remove_nodes_from(leaves)\n",
    "    H = H.to_undirected()\n",
    "    return H\n",
    "\n",
    "def compute_J_i_arrow_j(clique_tree, i, j, J, h, J_messages, h_messages, globalcounter):\n",
    "    \n",
    "    neighbors = list(clique_tree.neighbors(i))\n",
    "    neighbors.remove(j)\n",
    "\n",
    "    i_idx = mapping_GTM(i)\n",
    "    j_idx = mapping_GTM(j)\n",
    "\n",
    "    if not neighbors:\n",
    "        J_messages[i_idx][j_idx] = -J[i_idx, j_idx] * J[j_idx, i_idx] / J[i_idx, i_idx]\n",
    "        globalcounter[0] += 1\n",
    "    else:\n",
    "        J_sum = np.sum(compute_J_i_arrow_j(clique_tree, k, i, J, h, J_messages, h_messages, globalcounter) for k in neighbors)\n",
    "        J_messages[i_idx][j_idx] = -J[i_idx, j_idx] * J[j_idx, i_idx] / (J[i_idx, i_idx] + J_sum)\n",
    "        globalcounter[0] += 1\n",
    "\n",
    "    return J_messages[i_idx][j_idx]\n",
    "\n",
    "\n",
    "def compute_h_i_arrow_j(clique_tree, i, j, J, h, J_messages, h_messages, globalcounter):\n",
    "\n",
    "    neighbors = list(clique_tree.neighbors(i))\n",
    "    neighbors.remove(j)\n",
    "\n",
    "    i_idx = mapping_GTM(i)\n",
    "    j_idx = mapping_GTM(j)\n",
    "\n",
    "    if not neighbors:\n",
    "        h_messages[i_idx][j_idx] = -J[i_idx, j_idx] * h[i_idx] / J[i_idx, i_idx]\n",
    "        globalcounter[1] += 1\n",
    "    else:\n",
    "        J_sum = np.sum(compute_J_i_arrow_j(clique_tree, k, i, J, h, J_messages, h_messages, globalcounter) for k in neighbors)\n",
    "        h_sum = np.sum(compute_h_i_arrow_j(clique_tree, k, i, J, h, J_messages, h_messages, globalcounter) for k in neighbors)\n",
    "        Ji_backslash_j = J[i_idx, i_idx] + J_sum\n",
    "        hi_backslash_j = h[i_idx] + h_sum\n",
    "        h_messages[i_idx][j_idx] = (-J[i_idx, j_idx] * hi_backslash_j) / (Ji_backslash_j)\n",
    "        globalcounter[0] += 1\n",
    "\n",
    "    return h_messages[i_idx][j_idx]\n",
    "\n",
    "def inference_algorithm(full_tree, J, h, observed_X, Z, globalcounter):\n",
    "    clique_tree = single_clique(full_tree)\n",
    "\n",
    "    print(\"Number of nodes in clique tree:\", len(clique_tree.nodes))\n",
    "\n",
    "    n_observed = len(observed_X)\n",
    "    J_reduced, h_reduced = get_conditional_distribution(J, h, observed_X, list(range(1, n_observed + 1)))\n",
    "\n",
    "\n",
    "    J_messages = np.full(J_reduced.shape, np.nan)\n",
    "    h_messages = np.full(J_reduced.shape, np.nan)\n",
    "\n",
    "    Z_neighbors = list(clique_tree.neighbors(Z))\n",
    "    Z_idx = mapping_GTM(Z)\n",
    "\n",
    "    J_zz = J_reduced[Z_idx, Z_idx]\n",
    "\n",
    "    # print(\"Z neighbors:\", Z_neighbors)\n",
    "    # print(\"Z index:\", Z_idx)\n",
    "    sum_J = np.sum([compute_J_i_arrow_j(clique_tree, k, Z, J_reduced, h_reduced, J_messages, h_messages, globalcounter) for k in Z_neighbors])\n",
    "    sum_h = np.sum([compute_h_i_arrow_j(clique_tree, k, Z, J_reduced, h_reduced, J_messages, h_messages, globalcounter) for k in Z_neighbors])\n",
    "\n",
    "    J_hat_Z = J_zz + sum_J\n",
    "    h_hat_Z = h_reduced[Z_idx] + sum_h\n",
    "\n",
    "    # print(f\"J_zz for node {Z}:\", J_zz)\n",
    "    # print(\"Incoming J messages:\")\n",
    "    # for k in Z_neighbors:\n",
    "    #     val = compute_J_i_arrow_j(clique_tree, k, Z, J_reduced, h_reduced, J_messages, h_messages, globalcounter)\n",
    "    #     h_val = compute_h_i_arrow_j(clique_tree, k, Z, J_reduced, h_reduced, J_messages, h_messages, globalcounter)\n",
    "    #     print(f\"  {k} → {Z}: {val} ({h_val})\")\n",
    "\n",
    "    # print(\"→ Sum of messages:\", sum_J)\n",
    "\n",
    "    return J_hat_Z, h_hat_Z\n",
    "\n",
    "def information_to_standard(J_hat_Z, h_hat_Z, Z):\n",
    "\n",
    "    print(\"J_hat_Z:\", J_hat_Z)\n",
    "    print(\"h_hat_Z:\", h_hat_Z)\n",
    "    mu = h_hat_Z / J_hat_Z\n",
    "    sigma = np.sqrt(1 / J_hat_Z)\n",
    "    return mu, sigma\n",
    "\n",
    "n = 10\n",
    "random_index = np.random.choice(range(n))\n",
    "Z = 300  # root node\n",
    "\n",
    "alpha = 0\n",
    "beta = 1\n",
    "sigma_sq = 2500\n",
    "\n",
    "X_values, _ = simulate_data_for_learning(G, n, alpha = alpha, beta = beta, sigma_sq = sigma_sq, alpha_0 = 50000, sigma_0_sq = 5000, root = 407, learn_params=False, only_X=True)\n",
    "\n",
    "globalcounter = [0,0]\n",
    "\n",
    "J_hat_Z, h_hat_Z = inference_algorithm(G, J, h, X_values[random_index], Z, globalcounter)\n",
    "mu, sigma = information_to_standard(J_hat_Z, h_hat_Z, Z)\n",
    "\n",
    "true_mu = X_values[random_index][0]\n",
    "true_sigma = sigma_sq\n",
    "print(\"True mean:\", true_mu)\n",
    "print(\"True std dev:\", true_sigma)\n",
    "print(\"Posterior mean:\", mu)\n",
    "print(\"Posterior std dev:\", sigma)\n",
    "print(\"Total messages sent:\", globalcounter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
