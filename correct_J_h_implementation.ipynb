{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1509,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1510,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "tree = pd.read_csv('tree.csv')\n",
    "tree['t'] = tree['t'].replace(to_replace=0, value=0.1)\n",
    "\n",
    "vert_genes = pd.read_csv('vert_genes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1511,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the graph\n",
    "\n",
    "def create_graph(tree, alpha, beta, sigma_sq):\n",
    "    G = nx.DiGraph()\n",
    "    for _, row in tree.iterrows():\n",
    "        if not pd.isna(row['Parent']):\n",
    "            G.add_edge(int(row[\"Parent\"]), int(row[\"Child\"]), time = row[\"t\"], a = alpha*row[\"t\"], b = beta, variance = sigma_sq*row[\"t\"])\n",
    "            \n",
    "    return G\n",
    "\n",
    "G = create_graph(tree, alpha = 0, beta = 1, sigma_sq = 2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1512,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_node_length_with_parameters(G, parent, simulated_lengths, alpha, beta, sigma_sq):\n",
    "    for child in G.successors(parent):\n",
    "        t = G[parent][child]['time']\n",
    "        mean = alpha * t + beta * simulated_lengths[parent]\n",
    "        std = np.sqrt(sigma_sq * t)\n",
    "        simulated_lengths[child] = np.random.normal(mean, std)\n",
    "        simulate_node_length_with_parameters(G, child, simulated_lengths, alpha, beta, sigma_sq)\n",
    "    \n",
    "    return simulated_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 204)\n",
      "(1000,)\n",
      "50021.688551369116\n"
     ]
    }
   ],
   "source": [
    "def simulate_data_for_learning(G, n, alpha, beta, sigma_sq, alpha_0, sigma_0_sq, root, learn_params = True, only_X = True):\n",
    "    X_values = []\n",
    "    Y_values = []\n",
    "    \n",
    "    all_nodes = list(G.nodes)  # Get all nodes in the graph\n",
    "\n",
    "    for _ in range(n):\n",
    "        simulated_lengths = {}\n",
    "        \n",
    "        # Simulate root node first\n",
    "        simulated_lengths[root] = np.random.normal(alpha_0, np.sqrt(sigma_0_sq))\n",
    "        \n",
    "        # Simulate all other nodes recursively\n",
    "        simulated_lengths = simulate_node_length_with_parameters(G, root, simulated_lengths, alpha, beta, sigma_sq)\n",
    "        if only_X:\n",
    "            leaf_nodes = [node for node in all_nodes if G.out_degree(node) == 0]\n",
    "            simulated_x = [simulated_lengths[node] for node in leaf_nodes]\n",
    "            \n",
    "            X_values.append(simulated_x)\n",
    "        else:\n",
    "            X_values.append([simulated_lengths[node] for node in all_nodes])\n",
    "            \n",
    "        if learn_params:\n",
    "            Y_values.append([alpha,beta,sigma_sq])\n",
    "        else:\n",
    "            Y_values.append(simulated_lengths[root])\n",
    "\n",
    "    return np.array(X_values), np.array(Y_values)\n",
    "\n",
    "learn_parameters = False\n",
    "\n",
    "X, y = simulate_data_for_learning(G, 1000, alpha = 0.5, beta = 1, sigma_sq = 2500, alpha_0 = 50000, sigma_0_sq = 5000, root = 407, learn_params=learn_parameters)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "print(y[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1514,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gamma(G):\n",
    "    gamma = np.eye(len(G.nodes)) # Initialize gamma as an identity matrix\n",
    "\n",
    "    # Iterate through the nodes in the graph\n",
    "    for node in G.nodes:\n",
    "        parent = next(G.predecessors(node), None)\n",
    "        if parent is None:\n",
    "            continue\n",
    "        else:\n",
    "            gamma[parent-1, node -1] = -G[parent][node]['b'] # Determine the dependency between parent and child nodes with -b\n",
    "    return gamma\n",
    "\n",
    "def compute_beta(G, alpha_0):\n",
    "    beta = np.zeros((len(G.nodes), 1))\n",
    "    for node in G.nodes:\n",
    "        parent = next(G.predecessors(node), None)\n",
    "        if parent is None:\n",
    "            beta[node-1] = alpha_0\n",
    "            continue\n",
    "        a = G[parent][node]['a'] # The constant term in the mean of the CPD\n",
    "        beta[node-1] = a\n",
    "        \n",
    "    return beta\n",
    "\n",
    "def compute_sigma(G, sigma_0_sq):\n",
    "    sigma = np.zeros((len(G.nodes)))\n",
    "    for node in G.nodes:\n",
    "        parent = next(G.predecessors(node), None)\n",
    "        if parent is None:\n",
    "            # Assign the default value for the root node\n",
    "            sigma[node - 1] = sigma_0_sq\n",
    "        else:\n",
    "            # Access the edge attribute 'variance' only if parent exists\n",
    "            variance = G[parent][node]['variance']\n",
    "            sigma[node - 1] = variance\n",
    "    return sigma\n",
    "\n",
    "def compute_J_and_h(G, alpha, beta, sigma_sq, sigma_0_sq, alpha_0):\n",
    "    \n",
    "    beta = compute_beta(G, alpha_0)\n",
    "    sigma = compute_sigma(G, sigma_0_sq)\n",
    "    gamma = compute_gamma(G)\n",
    "\n",
    "    J = np.sum([np.outer(gamma[:, i], gamma[:, i]) / sigma[i] for i in range(len(G))], axis=0)\n",
    "    h = np.sum([(beta[i] / sigma[i]) * gamma[:, i] for i in range(len(G))], axis=0)\n",
    "    return J, h\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1515,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_clique_tree(G, Z_nodes = None):\n",
    "    C = nx.Graph()\n",
    "\n",
    "    G_working = G.copy()\n",
    "    if Z_nodes is not None:\n",
    "        leaves = [node for node in G_working.nodes \n",
    "                if G_working.out_degree(node) == 0 and node not in Z_nodes]\n",
    "    else:\n",
    "        leaves = [node for node in G_working.nodes if G_working.out_degree(node) == 0]\n",
    "\n",
    "    G_working.remove_nodes_from(leaves)\n",
    "\n",
    "\n",
    "    index = min(G_working.nodes) -1 if all(isinstance(n, int) for n in G_working.nodes) else 0\n",
    "\n",
    "    for node in G_working.nodes:\n",
    "        parent = node\n",
    "        children = list(G_working.neighbors(parent))\n",
    "        C.add_node(parent, variables=[parent])\n",
    "        for child in children:\n",
    "            pair_clique = index\n",
    "            C.add_node(pair_clique, variables=[parent, child])\n",
    "            C.add_edge(parent, pair_clique)\n",
    "            C.add_edge(pair_clique, child)\n",
    "            index = index - 1\n",
    "\n",
    "    return C\n",
    "\n",
    "C = compute_clique_tree(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix algebra implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1516,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub_matrices(scope, X_values, J, h):\n",
    "    X_indices = np.isin(scope, X_values)\n",
    "    Z_indices = ~X_indices\n",
    "\n",
    "    J_ZZ = J[Z_indices, :][:, Z_indices]\n",
    "    J_ZX = J[Z_indices, :][:, X_indices]\n",
    "    J_XZ = J_ZX.T\n",
    "    J_XX = J[X_indices, :][:, X_indices]\n",
    "    J_ZZ_inv = np.linalg.inv(J_ZZ)\n",
    "\n",
    "    h_X = h[X_indices]\n",
    "    h_Z = h[Z_indices]\n",
    "\n",
    "    return J_ZZ, J_ZX, J_XZ, J_XX, J_ZZ_inv, h_X, h_Z\n",
    "\n",
    "def get_conditional_distribution(J, h, X_values, X_indices, scope=None):\n",
    "    if scope is None:\n",
    "        scope = list(range(len(J)))  # zero-indexed scope\n",
    "\n",
    "    # Keep only indices in scope\n",
    "    X_indices = [i for i in X_indices if i in scope]\n",
    "    X_values = np.array([X_values[i] for i in range(len(X_indices))])\n",
    "\n",
    "    J_ZZ, J_ZX, J_XZ, J_XX, J_ZZ_inv, h_X, h_Z = get_sub_matrices(scope, X_indices, J, h)\n",
    "\n",
    "    print(\"J_ZX shape:\", J_ZX.shape)\n",
    "    print(\"X_values shape:\", X_values.shape)\n",
    "\n",
    "    J_reduced = J_ZZ\n",
    "    h_reduced = h_Z - J_ZX @ X_values\n",
    "\n",
    "    Z_nodes = [i for i in scope if i not in X_indices]\n",
    "    return J_reduced, h_reduced, Z_nodes\n",
    "\n",
    "\n",
    "alpha = 0.5\n",
    "beta = 1\n",
    "sigma_sq = 2500\n",
    "\n",
    "X_values = simulate_data_for_learning(G, 1, alpha=alpha, beta=beta, sigma_sq=sigma_sq, alpha_0=50000, sigma_0_sq=5000, root=407, learn_params=False, only_X=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing matrix algebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "Predicted value for node 407: 50210.41836692705\n",
      "Variance for node 407: 5172.497973433895\n",
      "Actual value for node 407: 49686.31055858546\n",
      "True variance for node 407: 2500\n"
     ]
    }
   ],
   "source": [
    "leaves = [node for node in G.nodes if G.out_degree(node) == 0]\n",
    "X_indices = leaves\n",
    "\n",
    "J, h = compute_J_and_h(G, alpha, beta, sigma_sq, 5000, 50000)\n",
    "\n",
    "J_reduced, h_reduced, Z_nodes = get_conditional_distribution(J, h, X_values[0], X_indices)\n",
    "\n",
    "\n",
    "Sigma = np.linalg.inv(J_reduced)\n",
    "mu = Sigma @ h_reduced\n",
    "\n",
    "random_index = np.random.choice(range(len(X_values[0])))\n",
    "z = random_index\n",
    "print(f\"Predicted value for node 407: {mu[z]}\")\n",
    "print(f\"Variance for node 407: {Sigma[z,z]}\")\n",
    "print(f\"Actual value for node 407: {X_values[0][0]}\")\n",
    "print(f\"True variance for node 407: {sigma_sq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II : inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1518,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marginalize_out(J, h, X_indices):\n",
    "    scope = [i for i in range(1, len(J) + 1)]\n",
    "    J_ZZ, J_ZX, J_XZ, J_XX, J_ZZ_inv, h_X, h_Z = get_sub_matrices(scope, X_indices, J, h)\n",
    "\n",
    "    J_marg = J_ZZ - (J_ZX @ np.linalg.inv(J_XX) @ J_XZ)\n",
    "    h_marg = h_Z - (J_ZX @ np.linalg.inv(J_XX) @ h_X)\n",
    "\n",
    "    return J_marg, h_marg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1519,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NoV = len([node for node in C.nodes if len(C.nodes[node]['variables']) == 1]) -1\n",
    "maxIndex = max([node for node in C.nodes])\n",
    "away_from_zero = maxIndex - NoV\n",
    "minIndex = min([node for node in C.nodes if len(C.nodes[node]['variables']) == 1])\n",
    "\n",
    "def mapping_GTM(index_in_graph):\n",
    "    return index_in_graph - away_from_zero \n",
    "\n",
    "def mapping_MTG(index_in_matrix):\n",
    "    return index_in_matrix + away_from_zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rekuriv l√∏sning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1520,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_clique(G):\n",
    "    leaves = [node for node in G.nodes if G.out_degree(node) == 0]\n",
    "    H = G.copy()\n",
    "    H.remove_nodes_from(leaves)\n",
    "    H = H.to_undirected()\n",
    "    return H\n",
    "\n",
    "def compute_J_i_arrow_j(clique_tree, i, j, J, h, J_messages, h_messages):\n",
    "    \n",
    "    neighbors = list(clique_tree.neighbors(i))\n",
    "    neighbors.remove(j)\n",
    "\n",
    "    i_idx = mapping_GTM(i)\n",
    "    j_idx = mapping_GTM(j)\n",
    "\n",
    "    if not neighbors:\n",
    "        J_messages[i_idx][j_idx] = -J[i_idx, j_idx] * J[j_idx, i_idx] / J[i_idx, i_idx]\n",
    "    else:\n",
    "        J_sum = sum(compute_J_i_arrow_j(clique_tree, k, i, J, h, J_messages, h_messages) for k in neighbors)\n",
    "        J_messages[i_idx][j_idx] = -J[i_idx, j_idx] * J[j_idx, i_idx] / (J[i_idx, i_idx] + J_sum)\n",
    "\n",
    "    return J_messages[i_idx][j_idx]\n",
    "\n",
    "\n",
    "def compute_h_i_arrow_j(clique_tree, i, j, J, h, J_messages, h_messages):\n",
    "\n",
    "    neighbors = list(clique_tree.neighbors(i))\n",
    "    neighbors.remove(j)\n",
    "\n",
    "    i_idx = mapping_GTM(i)\n",
    "    j_idx = mapping_GTM(j)\n",
    "\n",
    "    if not neighbors:\n",
    "        h_messages[i_idx][j_idx] = -J[i_idx, j_idx] * h[i_idx] / J[i_idx, i_idx]\n",
    "    else:\n",
    "        J_sum = sum(compute_J_i_arrow_j(clique_tree, k, i, J, h, J_messages, h_messages) for k in neighbors)\n",
    "        h_sum = sum(compute_h_i_arrow_j(clique_tree, k, i, J, h, J_messages, h_messages) for k in neighbors)\n",
    "        Ji_backslash_j = J[i_idx, i_idx] + J_sum\n",
    "        hi_backslash_j = h[i_idx] + h_sum\n",
    "        h_messages[i_idx][j_idx] = (-J[i_idx, j_idx] * hi_backslash_j) / (Ji_backslash_j)\n",
    "\n",
    "    return h_messages[i_idx][j_idx]\n",
    "\n",
    "def inference_algorithm(G, alpha, beta, sigma_sq, alpha_0, X_indices, observed_X, Z):\n",
    "\n",
    "    clique_tree = single_clique(G)\n",
    "    J, h = compute_J_and_h(G, alpha, beta, sigma_sq, 5000, alpha_0)\n",
    "\n",
    "    J_reduced, h_reduced, Z_nodes = get_conditional_distribution(J, h, observed_X, X_indices)\n",
    "        \n",
    "    J_messages = np.full(J_reduced.shape, np.nan)\n",
    "    h_messages = np.full(J_reduced.shape, np.nan)\n",
    "\n",
    "    Z_neighbors = list(clique_tree.neighbors(Z))\n",
    "    Z_idx = mapping_GTM(Z)\n",
    "\n",
    "    J_zz = J_reduced[Z_idx, Z_idx]\n",
    "\n",
    "    sum_J = sum([compute_J_i_arrow_j(clique_tree, k, Z, J_reduced, h_reduced, J_messages, h_messages) for k in Z_neighbors])\n",
    "    sum_h = sum([compute_h_i_arrow_j(clique_tree, k, Z, J_reduced, h_reduced, J_messages, h_messages) for k in Z_neighbors])\n",
    "\n",
    "    J_hat_Z = J_zz + sum_J\n",
    "    h_hat_Z = h_reduced[Z_idx] + sum_h\n",
    "\n",
    "\n",
    "    return J_hat_Z, h_hat_Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1521,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "Maximum value:  50547.73974249449\n",
      "Minimum value:  0.0\n",
      "Node 205:\n",
      "Predicted value: 0.0\n",
      "Predicted variance: 22500.625\n",
      "True value: 49686.31055858546\n",
      "True variance: 2500\n",
      "\n",
      "Node 206:\n",
      "Predicted value: 50134.18874752156\n",
      "Predicted variance: 7274.790987326857\n",
      "True value: 49902.18684272899\n",
      "True variance: 2500\n",
      "\n",
      "Node 207:\n",
      "Predicted value: 50051.69990132598\n",
      "Predicted variance: 8327.21799919283\n",
      "True value: 49722.065955083264\n",
      "True variance: 2500\n",
      "\n",
      "Node 208:\n",
      "Predicted value: 49962.823163021865\n",
      "Predicted variance: 8234.784716334272\n",
      "True value: 49731.71400580065\n",
      "True variance: 2500\n",
      "\n",
      "Node 209:\n",
      "Predicted value: 49910.42905469723\n",
      "Predicted variance: 7950.403071787683\n",
      "True value: 49890.79262851493\n",
      "True variance: 2500\n",
      "\n",
      "Node 210:\n",
      "Predicted value: 49830.43578379756\n",
      "Predicted variance: 8140.654580665694\n",
      "True value: 50032.02129053866\n",
      "True variance: 2500\n",
      "\n",
      "Node 211:\n",
      "Predicted value: 49715.41574990143\n",
      "Predicted variance: 7932.149578478793\n",
      "True value: 49922.40367026839\n",
      "True variance: 2500\n",
      "\n",
      "Node 212:\n",
      "Predicted value: 49608.49070101679\n",
      "Predicted variance: 6411.7269650129865\n",
      "True value: 50105.25840054072\n",
      "True variance: 2500\n",
      "\n",
      "Node 213:\n",
      "Predicted value: 49343.24504011038\n",
      "Predicted variance: 7625.286740613967\n",
      "True value: 50016.51930089031\n",
      "True variance: 2500\n",
      "\n",
      "Node 214:\n",
      "Predicted value: 49096.82622627281\n",
      "Predicted variance: 8006.4584741997005\n",
      "True value: 49692.892059003316\n",
      "True variance: 2500\n",
      "\n",
      "Node 215:\n",
      "Predicted value: 48717.71048773947\n",
      "Predicted variance: 8362.991876278487\n",
      "True value: 49962.902899131026\n",
      "True variance: 2500\n",
      "\n",
      "Node 216:\n",
      "Predicted value: 48205.98633113431\n",
      "Predicted variance: 8321.234813177969\n",
      "True value: 49984.15192510825\n",
      "True variance: 2500\n",
      "\n",
      "Node 217:\n",
      "Predicted value: 47617.10277681406\n",
      "Predicted variance: 8141.718128913586\n",
      "True value: 49841.2063382277\n",
      "True variance: 2500\n",
      "\n",
      "Node 218:\n",
      "Predicted value: 46751.80305228432\n",
      "Predicted variance: 7937.912453318879\n",
      "True value: 49900.39763950415\n",
      "True variance: 2500\n",
      "\n",
      "Node 219:\n",
      "Predicted value: 45472.52755981208\n",
      "Predicted variance: 7703.011763413061\n",
      "True value: 50475.20958956478\n",
      "True variance: 2500\n",
      "\n",
      "Node 220:\n",
      "Predicted value: 43516.6463359611\n",
      "Predicted variance: 7449.398000397952\n",
      "True value: 50326.012204010105\n",
      "True variance: 2500\n",
      "\n",
      "Node 221:\n",
      "Predicted value: 40390.08230055588\n",
      "Predicted variance: 7261.107987762799\n",
      "True value: 50370.360488829865\n",
      "True variance: 2500\n",
      "\n",
      "Node 222:\n",
      "Predicted value: 33961.74424273562\n",
      "Predicted variance: 7149.640887787315\n",
      "True value: 50346.78851058677\n",
      "True variance: 2500\n",
      "\n",
      "Node 223:\n",
      "Predicted value: 49807.47839809578\n",
      "Predicted variance: 5527.423661126255\n",
      "True value: 50341.506155148105\n",
      "True variance: 2500\n",
      "\n",
      "Node 224:\n",
      "Predicted value: 49834.172079142016\n",
      "Predicted variance: 4577.4902951089325\n",
      "True value: 50384.587411120614\n",
      "True variance: 2500\n",
      "\n",
      "Node 225:\n",
      "Predicted value: 49863.3505009652\n",
      "Predicted variance: 4188.555686987082\n",
      "True value: 50345.802669593126\n",
      "True variance: 2500\n",
      "\n",
      "Node 226:\n",
      "Predicted value: 49886.95983906972\n",
      "Predicted variance: 4059.006316966516\n",
      "True value: 50489.22246012453\n",
      "True variance: 2500\n",
      "\n",
      "Node 227:\n",
      "Predicted value: 49660.39722937429\n",
      "Predicted variance: 6571.645907773886\n",
      "True value: 50275.02389948205\n",
      "True variance: 2500\n",
      "\n",
      "Node 228:\n",
      "Predicted value: 49745.3388268502\n",
      "Predicted variance: 6808.607115814515\n",
      "True value: 50305.387335417625\n",
      "True variance: 2500\n",
      "\n",
      "Node 229:\n",
      "Predicted value: 49832.33609525227\n",
      "Predicted variance: 7449.808127429974\n",
      "True value: 50190.75801322444\n",
      "True variance: 2500\n",
      "\n",
      "Node 230:\n",
      "Predicted value: 49932.80533261229\n",
      "Predicted variance: 7068.879684096237\n",
      "True value: 49894.909552030964\n",
      "True variance: 2500\n",
      "\n",
      "Node 231:\n",
      "Predicted value: 50006.14674888207\n",
      "Predicted variance: 6537.112369428588\n",
      "True value: 49789.35816390726\n",
      "True variance: 2500\n",
      "\n",
      "Node 232:\n",
      "Predicted value: 50074.0553790256\n",
      "Predicted variance: 6157.401224173698\n",
      "True value: 50515.810561822494\n",
      "True variance: 2500\n",
      "\n",
      "Node 233:\n",
      "Predicted value: 50111.03984286524\n",
      "Predicted variance: 6614.11311172915\n",
      "True value: 50475.000143347104\n",
      "True variance: 2500\n",
      "\n",
      "Node 234:\n",
      "Predicted value: 50164.27012772262\n",
      "Predicted variance: 6723.825028654304\n",
      "True value: 50520.02939539384\n",
      "True variance: 2500\n",
      "\n",
      "Node 235:\n",
      "Predicted value: 50226.74149100959\n",
      "Predicted variance: 6643.95927527904\n",
      "True value: 50267.40097890432\n",
      "True variance: 2500\n",
      "\n",
      "Node 236:\n",
      "Predicted value: 50314.60207473238\n",
      "Predicted variance: 4744.935290184874\n",
      "True value: 50026.82579365411\n",
      "True variance: 2500\n",
      "\n",
      "Node 237:\n",
      "Predicted value: 50333.93056871838\n",
      "Predicted variance: 4323.470405582502\n",
      "True value: 50039.353961188936\n",
      "True variance: 2500\n",
      "\n",
      "Node 238:\n",
      "Predicted value: 50336.189302617255\n",
      "Predicted variance: 4399.410703527465\n",
      "True value: 50176.0582576192\n",
      "True variance: 2500\n",
      "\n",
      "Node 239:\n",
      "Predicted value: 50366.70519264937\n",
      "Predicted variance: 2676.1280812993123\n",
      "True value: 50085.33281452518\n",
      "True variance: 2500\n",
      "\n",
      "Node 240:\n",
      "Predicted value: 50378.349993244956\n",
      "Predicted variance: 1836.2422666933867\n",
      "True value: 50438.75723582191\n",
      "True variance: 2500\n",
      "\n",
      "Node 241:\n",
      "Predicted value: 50385.77029442579\n",
      "Predicted variance: 1649.4410074192829\n",
      "True value: 50085.786878951854\n",
      "True variance: 2500\n",
      "\n",
      "Node 242:\n",
      "Predicted value: 50358.915987494955\n",
      "Predicted variance: 3171.2512259446294\n",
      "True value: 50418.807179054435\n",
      "True variance: 2500\n",
      "\n",
      "Node 243:\n",
      "Predicted value: 50317.85430929639\n",
      "Predicted variance: 4931.030789299864\n",
      "True value: 50417.091958329154\n",
      "True variance: 2500\n",
      "\n",
      "Node 244:\n",
      "Predicted value: 50193.40498047344\n",
      "Predicted variance: 6401.407336423904\n",
      "True value: 50688.576534076856\n",
      "True variance: 2500\n",
      "\n",
      "Node 245:\n",
      "Predicted value: 50234.78376082917\n",
      "Predicted variance: 5570.9651827731\n",
      "True value: 50515.31952461812\n",
      "True variance: 2500\n",
      "\n",
      "Node 246:\n",
      "Predicted value: 50251.81960983992\n",
      "Predicted variance: 5395.890537080204\n",
      "True value: 50516.98608218514\n",
      "True variance: 2500\n",
      "\n",
      "Node 247:\n",
      "Predicted value: 50288.01655780682\n",
      "Predicted variance: 5518.573066254706\n",
      "True value: 50343.81668113925\n",
      "True variance: 2500\n",
      "\n",
      "Node 248:\n",
      "Predicted value: 50279.68398877865\n",
      "Predicted variance: 3985.934838370457\n",
      "True value: 50326.15639015079\n",
      "True variance: 2500\n",
      "\n",
      "Node 249:\n",
      "Predicted value: 50230.79951727335\n",
      "Predicted variance: 3432.5433707438415\n",
      "True value: 50064.70734744479\n",
      "True variance: 2500\n",
      "\n",
      "Node 250:\n",
      "Predicted value: 50137.03570449578\n",
      "Predicted variance: 1843.3978063848247\n",
      "True value: 50108.115585894404\n",
      "True variance: 2500\n",
      "\n",
      "Node 251:\n",
      "Predicted value: 50129.856609544484\n",
      "Predicted variance: 1618.1835810134014\n",
      "True value: 50097.03314015384\n",
      "True variance: 2500\n",
      "\n",
      "Node 252:\n",
      "Predicted value: 50138.48511295549\n",
      "Predicted variance: 1342.0476074118997\n",
      "True value: 49987.3951753544\n",
      "True variance: 2500\n",
      "\n",
      "Node 253:\n",
      "Predicted value: 50336.931800380014\n",
      "Predicted variance: 3065.432971618579\n",
      "True value: 50191.76096639823\n",
      "True variance: 2500\n",
      "\n",
      "Node 254:\n",
      "Predicted value: 50298.771421700585\n",
      "Predicted variance: 3285.161437576796\n",
      "True value: 49706.00298443233\n",
      "True variance: 2500\n",
      "\n",
      "Node 255:\n",
      "Predicted value: 50364.13438268121\n",
      "Predicted variance: 2402.7508615702327\n",
      "True value: 49900.101685941285\n",
      "True variance: 2500\n",
      "\n",
      "Node 256:\n",
      "Predicted value: 50387.083788557495\n",
      "Predicted variance: 1966.8005684739214\n",
      "True value: 49872.52381179214\n",
      "True variance: 2500\n",
      "\n",
      "Node 257:\n",
      "Predicted value: 50387.62311251473\n",
      "Predicted variance: 1948.2525233754536\n",
      "True value: 50025.946610669234\n",
      "True variance: 2500\n",
      "\n",
      "Node 258:\n",
      "Predicted value: 50336.49992541037\n",
      "Predicted variance: 2407.0641868278303\n",
      "True value: 49730.4387288177\n",
      "True variance: 2500\n",
      "\n",
      "Node 259:\n",
      "Predicted value: 50476.29168492479\n",
      "Predicted variance: 1952.7845650039978\n",
      "True value: 50003.13224141797\n",
      "True variance: 2500\n",
      "\n",
      "Node 260:\n",
      "Predicted value: 50498.16098814714\n",
      "Predicted variance: 1889.1757984714272\n",
      "True value: 49857.91243169139\n",
      "True variance: 2500\n",
      "\n",
      "Node 261:\n",
      "Predicted value: 50165.50870600067\n",
      "Predicted variance: 3725.577976294765\n",
      "True value: 49880.53633939766\n",
      "True variance: 2500\n",
      "\n",
      "Node 262:\n",
      "Predicted value: 50179.110173311536\n",
      "Predicted variance: 2812.981565579318\n",
      "True value: 49722.89765173738\n",
      "True variance: 2500\n",
      "\n",
      "Node 263:\n",
      "Predicted value: 49963.264723057524\n",
      "Predicted variance: 6318.275682422551\n",
      "True value: 50197.13970203056\n",
      "True variance: 2500\n",
      "\n",
      "Node 264:\n",
      "Predicted value: 49971.30391089419\n",
      "Predicted variance: 4758.651361690649\n",
      "True value: 49699.478306225144\n",
      "True variance: 2500\n",
      "\n",
      "Node 265:\n",
      "Predicted value: 49992.74189250301\n",
      "Predicted variance: 5150.573945657968\n",
      "True value: 49956.14697377389\n",
      "True variance: 2500\n",
      "\n",
      "Node 266:\n",
      "Predicted value: 49953.031498196404\n",
      "Predicted variance: 4308.878651702215\n",
      "True value: 49781.383047551426\n",
      "True variance: 2500\n",
      "\n",
      "Node 267:\n",
      "Predicted value: 49951.99411750115\n",
      "Predicted variance: 4298.744241582497\n",
      "True value: 49916.73492581986\n",
      "True variance: 2500\n",
      "\n",
      "Node 268:\n",
      "Predicted value: 49940.94545222509\n",
      "Predicted variance: 7084.260953611402\n",
      "True value: 49829.986124204814\n",
      "True variance: 2500\n",
      "\n",
      "Node 269:\n",
      "Predicted value: 49909.488816685\n",
      "Predicted variance: 5926.134817240808\n",
      "True value: 49871.687037523654\n",
      "True variance: 2500\n",
      "\n",
      "Node 270:\n",
      "Predicted value: 49903.680560765526\n",
      "Predicted variance: 4912.727373053532\n",
      "True value: 49553.92467813103\n",
      "True variance: 2500\n",
      "\n",
      "Node 271:\n",
      "Predicted value: 49886.00628647292\n",
      "Predicted variance: 3928.8895602565\n",
      "True value: 49688.31609049599\n",
      "True variance: 2500\n",
      "\n",
      "Node 272:\n",
      "Predicted value: 49905.79930582521\n",
      "Predicted variance: 4620.190417409736\n",
      "True value: 49691.28700230884\n",
      "True variance: 2500\n",
      "\n",
      "Node 273:\n",
      "Predicted value: 49923.123587022455\n",
      "Predicted variance: 3041.537911912641\n",
      "True value: 49898.37486737242\n",
      "True variance: 2500\n",
      "\n",
      "Node 274:\n",
      "Predicted value: 49828.77183838037\n",
      "Predicted variance: 9691.790475868882\n",
      "True value: 49943.067657190324\n",
      "True variance: 2500\n",
      "\n",
      "Node 275:\n",
      "Predicted value: 49867.97695061659\n",
      "Predicted variance: 7299.839141540685\n",
      "True value: 49953.906662465924\n",
      "True variance: 2500\n",
      "\n",
      "Node 276:\n",
      "Predicted value: 49889.69741460436\n",
      "Predicted variance: 6537.474260674905\n",
      "True value: 49944.3315036487\n",
      "True variance: 2500\n",
      "\n",
      "Node 277:\n",
      "Predicted value: 49890.67121250516\n",
      "Predicted variance: 6123.445627801195\n",
      "True value: 49560.33121851096\n",
      "True variance: 2500\n",
      "\n",
      "Node 278:\n",
      "Predicted value: 49888.960837271654\n",
      "Predicted variance: 5888.021134183899\n",
      "True value: 49788.612589096876\n",
      "True variance: 2500\n",
      "\n",
      "Node 279:\n",
      "Predicted value: 49878.700494062796\n",
      "Predicted variance: 5319.288756966951\n",
      "True value: 49785.643401071924\n",
      "True variance: 2500\n",
      "\n",
      "Node 280:\n",
      "Predicted value: 49850.57489755623\n",
      "Predicted variance: 4939.82576106959\n",
      "True value: 50113.440872311105\n",
      "True variance: 2500\n",
      "\n",
      "Node 281:\n",
      "Predicted value: 49849.799134301604\n",
      "Predicted variance: 3736.3450117010766\n",
      "True value: 49956.34495144455\n",
      "True variance: 2500\n",
      "\n",
      "Node 282:\n",
      "Predicted value: 49876.087710008054\n",
      "Predicted variance: 4643.639367918317\n",
      "True value: 50012.261143776195\n",
      "True variance: 2500\n",
      "\n",
      "Node 283:\n",
      "Predicted value: 49830.43716126104\n",
      "Predicted variance: 4711.235360344976\n",
      "True value: 50181.32483363737\n",
      "True variance: 2500\n",
      "\n",
      "Node 284:\n",
      "Predicted value: 49787.923036272674\n",
      "Predicted variance: 4346.755494854168\n",
      "True value: 50000.36802599999\n",
      "True variance: 2500\n",
      "\n",
      "Node 285:\n",
      "Predicted value: 49802.945720989956\n",
      "Predicted variance: 3390.9687247447173\n",
      "True value: 49944.41652310769\n",
      "True variance: 2500\n",
      "\n",
      "Node 286:\n",
      "Predicted value: 49724.61112842424\n",
      "Predicted variance: 1800.0727027245118\n",
      "True value: 49925.70832653421\n",
      "True variance: 2500\n",
      "\n",
      "Node 287:\n",
      "Predicted value: 49724.61103376247\n",
      "Predicted variance: 1800.0689016989024\n",
      "True value: 50096.39412023162\n",
      "True variance: 2500\n",
      "\n",
      "Node 288:\n",
      "Predicted value: 49862.5068205261\n",
      "Predicted variance: 2625.078657213346\n",
      "True value: 50037.7110638537\n",
      "True variance: 2500\n",
      "\n",
      "Node 289:\n",
      "Predicted value: 49877.130401566494\n",
      "Predicted variance: 1485.4465104974279\n",
      "True value: 49967.39249735468\n",
      "True variance: 2500\n",
      "\n",
      "Node 290:\n",
      "Predicted value: 49874.32444820662\n",
      "Predicted variance: 1419.6167577994702\n",
      "True value: 50049.28564177952\n",
      "True variance: 2500\n",
      "\n",
      "Node 291:\n",
      "Predicted value: 49834.57769152362\n",
      "Predicted variance: 1292.4041894498675\n",
      "True value: 50173.261377213574\n",
      "True variance: 2500\n",
      "\n",
      "Node 292:\n",
      "Predicted value: 49962.70656896242\n",
      "Predicted variance: 4595.310250290344\n",
      "True value: 50096.49468055056\n",
      "True variance: 2500\n",
      "\n",
      "Node 293:\n",
      "Predicted value: 49997.77350559765\n",
      "Predicted variance: 3783.6468141179525\n",
      "True value: 49739.35441006208\n",
      "True variance: 2500\n",
      "\n",
      "Node 294:\n",
      "Predicted value: 49980.323648377605\n",
      "Predicted variance: 2483.27372036005\n",
      "True value: 49690.045180980866\n",
      "True variance: 2500\n",
      "\n",
      "Node 295:\n",
      "Predicted value: 49974.23652106878\n",
      "Predicted variance: 2270.8606737156374\n",
      "True value: 49989.41480400312\n",
      "True variance: 2500\n",
      "\n",
      "Node 296:\n",
      "Predicted value: 49973.060598003234\n",
      "Predicted variance: 2297.8328106264303\n",
      "True value: 49828.41886693179\n",
      "True variance: 2500\n",
      "\n",
      "Node 297:\n",
      "Predicted value: 50034.64274360035\n",
      "Predicted variance: 4890.062730007081\n",
      "True value: 49845.55796003382\n",
      "True variance: 2500\n",
      "\n",
      "Node 298:\n",
      "Predicted value: 50030.463498339945\n",
      "Predicted variance: 3793.2319555048216\n",
      "True value: 50509.35017647269\n",
      "True variance: 2500\n",
      "\n",
      "Node 299:\n",
      "Predicted value: 50051.37155188436\n",
      "Predicted variance: 2839.5732163172124\n",
      "True value: 50114.77276267238\n",
      "True variance: 2500\n",
      "\n",
      "Node 300:\n",
      "Predicted value: 50085.4081081454\n",
      "Predicted variance: 3455.410917820568\n",
      "True value: 49661.46109114276\n",
      "True variance: 2500\n",
      "\n",
      "Node 301:\n",
      "Predicted value: 49865.72497333037\n",
      "Predicted variance: 7849.993864971186\n",
      "True value: 50087.80069394071\n",
      "True variance: 2500\n",
      "\n",
      "Node 302:\n",
      "Predicted value: 49874.129757393115\n",
      "Predicted variance: 6201.981601016596\n",
      "True value: 49949.20067816811\n",
      "True variance: 2500\n",
      "\n",
      "Node 303:\n",
      "Predicted value: 49852.92854333041\n",
      "Predicted variance: 5247.517276603488\n",
      "True value: 49997.44148731142\n",
      "True variance: 2500\n",
      "\n",
      "Node 304:\n",
      "Predicted value: 49889.216410377965\n",
      "Predicted variance: 4164.2314163043375\n",
      "True value: 49350.00649453659\n",
      "True variance: 2500\n",
      "\n",
      "Node 305:\n",
      "Predicted value: 50079.171953464465\n",
      "Predicted variance: 10361.437188010916\n",
      "True value: 49918.08206683326\n",
      "True variance: 2500\n",
      "\n",
      "Node 306:\n",
      "Predicted value: 49783.6384287566\n",
      "Predicted variance: 14273.015526786341\n",
      "True value: 49677.73605435148\n",
      "True variance: 2500\n",
      "\n",
      "Node 307:\n",
      "Predicted value: 49839.24681017413\n",
      "Predicted variance: 14682.364275942298\n",
      "True value: 50070.07951435756\n",
      "True variance: 2500\n",
      "\n",
      "Node 308:\n",
      "Predicted value: 49891.97117380784\n",
      "Predicted variance: 7858.2638336219225\n",
      "True value: 50475.87504405042\n",
      "True variance: 2500\n",
      "\n",
      "Node 309:\n",
      "Predicted value: 49881.566894072144\n",
      "Predicted variance: 5007.321979394292\n",
      "True value: 50193.76384525298\n",
      "True variance: 2500\n",
      "\n",
      "Node 310:\n",
      "Predicted value: 49955.735423038444\n",
      "Predicted variance: 12749.9152956974\n",
      "True value: 50087.84951836679\n",
      "True variance: 2500\n",
      "\n",
      "Node 311:\n",
      "Predicted value: 49917.740654022964\n",
      "Predicted variance: 15775.882322068499\n",
      "True value: 50016.56732648653\n",
      "True variance: 2500\n",
      "\n",
      "Node 312:\n",
      "Predicted value: 50073.128487210684\n",
      "Predicted variance: 15894.217842972474\n",
      "True value: 49943.4117821737\n",
      "True variance: 2500\n",
      "\n",
      "Node 313:\n",
      "Predicted value: 50231.005033442285\n",
      "Predicted variance: 9100.34369930996\n",
      "True value: 49929.350561292005\n",
      "True variance: 2500\n",
      "\n",
      "Node 314:\n",
      "Predicted value: 49961.758672767086\n",
      "Predicted variance: 17602.004478875213\n",
      "True value: 49892.43228728256\n",
      "True variance: 2500\n",
      "\n",
      "Node 315:\n",
      "Predicted value: 49990.375219026726\n",
      "Predicted variance: 11410.298039477384\n",
      "True value: 49861.81272638093\n",
      "True variance: 2500\n",
      "\n",
      "Node 316:\n",
      "Predicted value: 50044.8472917308\n",
      "Predicted variance: 2914.686532159346\n",
      "True value: 49686.706747466764\n",
      "True variance: 2500\n",
      "\n",
      "Node 317:\n",
      "Predicted value: 49912.85732001533\n",
      "Predicted variance: 2429.6840519312673\n",
      "True value: 50239.81448515847\n",
      "True variance: 2500\n",
      "\n",
      "Node 318:\n",
      "Predicted value: 50507.8116215195\n",
      "Predicted variance: 5564.816939343003\n",
      "True value: 50169.62227630418\n",
      "True variance: 2500\n",
      "\n",
      "Node 319:\n",
      "Predicted value: 50444.25866816996\n",
      "Predicted variance: 6765.958677175844\n",
      "True value: 49966.712829795004\n",
      "True variance: 2500\n",
      "\n",
      "Node 320:\n",
      "Predicted value: 50398.19468775926\n",
      "Predicted variance: 7912.712364155819\n",
      "True value: 50491.142993864465\n",
      "True variance: 2500\n",
      "\n",
      "Node 321:\n",
      "Predicted value: 50219.54377104582\n",
      "Predicted variance: 6971.762406669124\n",
      "True value: 50768.989674169636\n",
      "True variance: 2500\n",
      "\n",
      "Node 322:\n",
      "Predicted value: 50350.02242106265\n",
      "Predicted variance: 8832.753626454645\n",
      "True value: 50521.764454173026\n",
      "True variance: 2500\n",
      "\n",
      "Node 323:\n",
      "Predicted value: 50324.73599756997\n",
      "Predicted variance: 9188.971128866046\n",
      "True value: 50376.49919217439\n",
      "True variance: 2500\n",
      "\n",
      "Node 324:\n",
      "Predicted value: 50311.05719732758\n",
      "Predicted variance: 9144.664479475252\n",
      "True value: 50329.24856680042\n",
      "True variance: 2500\n",
      "\n",
      "Node 325:\n",
      "Predicted value: 50307.91109624663\n",
      "Predicted variance: 9051.569691889319\n",
      "True value: 50770.51193463647\n",
      "True variance: 2500\n",
      "\n",
      "Node 326:\n",
      "Predicted value: 50336.32782472671\n",
      "Predicted variance: 8124.63895594277\n",
      "True value: 50169.8106978048\n",
      "True variance: 2500\n",
      "\n",
      "Node 327:\n",
      "Predicted value: 50363.31224645505\n",
      "Predicted variance: 7229.820735183071\n",
      "True value: 50523.66005513124\n",
      "True variance: 2500\n",
      "\n",
      "Node 328:\n",
      "Predicted value: 50391.728039234906\n",
      "Predicted variance: 8903.526577643725\n",
      "True value: 50364.81171026484\n",
      "True variance: 2500\n",
      "\n",
      "Node 329:\n",
      "Predicted value: 50417.41489783639\n",
      "Predicted variance: 8827.194587888162\n",
      "True value: 50574.10167437003\n",
      "True variance: 2500\n",
      "\n",
      "Node 330:\n",
      "Predicted value: 50441.50634889322\n",
      "Predicted variance: 11041.78224324813\n",
      "True value: 50727.149413389314\n",
      "True variance: 2500\n",
      "\n",
      "Node 331:\n",
      "Predicted value: 50295.766065149866\n",
      "Predicted variance: 7558.246427672248\n",
      "True value: 50575.412721454195\n",
      "True variance: 2500\n",
      "\n",
      "Node 332:\n",
      "Predicted value: 50447.361273637085\n",
      "Predicted variance: 9987.206226732285\n",
      "True value: 50196.42764880888\n",
      "True variance: 2500\n",
      "\n",
      "Node 333:\n",
      "Predicted value: 50419.274332339715\n",
      "Predicted variance: 9719.734145480725\n",
      "True value: 50306.13588932767\n",
      "True variance: 2500\n",
      "\n",
      "Node 334:\n",
      "Predicted value: 50436.22075494427\n",
      "Predicted variance: 7493.25956309806\n",
      "True value: 50316.44311780232\n",
      "True variance: 2500\n",
      "\n",
      "Node 335:\n",
      "Predicted value: 50384.043429343415\n",
      "Predicted variance: 7400.765112927936\n",
      "True value: 49962.85539131741\n",
      "True variance: 2500\n",
      "\n",
      "Node 336:\n",
      "Predicted value: 50386.705010495316\n",
      "Predicted variance: 7285.218860239675\n",
      "True value: 50597.059437698554\n",
      "True variance: 2500\n",
      "\n",
      "Node 337:\n",
      "Predicted value: 50373.08517764318\n",
      "Predicted variance: 7711.04332832262\n",
      "True value: 50306.48553291653\n",
      "True variance: 2500\n",
      "\n",
      "Node 338:\n",
      "Predicted value: 50369.843382739855\n",
      "Predicted variance: 7717.460579381288\n",
      "True value: 50034.56031809777\n",
      "True variance: 2500\n",
      "\n",
      "Node 339:\n",
      "Predicted value: 50345.47190506436\n",
      "Predicted variance: 7762.1350789927355\n",
      "True value: 50712.26345646608\n",
      "True variance: 2500\n",
      "\n",
      "Node 340:\n",
      "Predicted value: 50359.35910961863\n",
      "Predicted variance: 7589.526412179513\n",
      "True value: 50555.85806967591\n",
      "True variance: 2500\n",
      "\n",
      "Node 341:\n",
      "Predicted value: 50380.48421311238\n",
      "Predicted variance: 7019.897391204632\n",
      "True value: 50390.95609197764\n",
      "True variance: 2500\n",
      "\n",
      "Node 342:\n",
      "Predicted value: 50397.31924693608\n",
      "Predicted variance: 6826.851618381275\n",
      "True value: 50504.259951169515\n",
      "True variance: 2500\n",
      "\n",
      "Node 343:\n",
      "Predicted value: 50464.15949673151\n",
      "Predicted variance: 6681.507444634024\n",
      "True value: 50525.47102258533\n",
      "True variance: 2500\n",
      "\n",
      "Node 344:\n",
      "Predicted value: 50525.18380948808\n",
      "Predicted variance: 5654.607753501537\n",
      "True value: 50565.8127966499\n",
      "True variance: 2500\n",
      "\n",
      "Node 345:\n",
      "Predicted value: 50511.30299321405\n",
      "Predicted variance: 4576.4288671292015\n",
      "True value: 50624.82817603784\n",
      "True variance: 2500\n",
      "\n",
      "Node 346:\n",
      "Predicted value: 50475.71526758546\n",
      "Predicted variance: 3661.3737925097857\n",
      "True value: 50665.59073895341\n",
      "True variance: 2500\n",
      "\n",
      "Node 347:\n",
      "Predicted value: 50448.18133568867\n",
      "Predicted variance: 8481.317983834992\n",
      "True value: 50425.86035868828\n",
      "True variance: 2500\n",
      "\n",
      "Node 348:\n",
      "Predicted value: 50445.848072687884\n",
      "Predicted variance: 8362.404755259819\n",
      "True value: 50656.958826925635\n",
      "True variance: 2500\n",
      "\n",
      "Node 349:\n",
      "Predicted value: 50430.03394348384\n",
      "Predicted variance: 8930.191074163502\n",
      "True value: 50352.37924168024\n",
      "True variance: 2500\n",
      "\n",
      "Node 350:\n",
      "Predicted value: 50520.094081105104\n",
      "Predicted variance: 5901.033322902205\n",
      "True value: 49950.21957559002\n",
      "True variance: 2500\n",
      "\n",
      "Node 351:\n",
      "Predicted value: 50537.1773372465\n",
      "Predicted variance: 5375.646937644099\n",
      "True value: 50013.84767349187\n",
      "True variance: 2500\n",
      "\n",
      "Node 352:\n",
      "Predicted value: 50547.73974249449\n",
      "Predicted variance: 3185.0698329151064\n",
      "True value: 49906.835122733864\n",
      "True variance: 2500\n",
      "\n",
      "Node 353:\n",
      "Predicted value: 50528.473980756375\n",
      "Predicted variance: 2239.5766031896424\n",
      "True value: 50100.93023143278\n",
      "True variance: 2500\n",
      "\n",
      "Node 354:\n",
      "Predicted value: 50493.65056910139\n",
      "Predicted variance: 1309.1040385109284\n",
      "True value: 50198.842348395214\n",
      "True variance: 2500\n",
      "\n",
      "Node 355:\n",
      "Predicted value: 50482.13941424856\n",
      "Predicted variance: 1205.1200244623865\n",
      "True value: 49845.963055760956\n",
      "True variance: 2500\n",
      "\n",
      "Node 356:\n",
      "Predicted value: 50102.940216943294\n",
      "Predicted variance: 2495.232748204068\n",
      "True value: 49962.28143677223\n",
      "True variance: 2500\n",
      "\n",
      "Node 357:\n",
      "Predicted value: 50130.57409998236\n",
      "Predicted variance: 1529.7363042410107\n",
      "True value: 50129.84467148355\n",
      "True variance: 2500\n",
      "\n",
      "Node 358:\n",
      "Predicted value: 50196.37568076168\n",
      "Predicted variance: 8625.542502780794\n",
      "True value: 50170.884822794134\n",
      "True variance: 2500\n",
      "\n",
      "Node 359:\n",
      "Predicted value: 50187.939836711965\n",
      "Predicted variance: 6951.152504376891\n",
      "True value: 50487.408500056816\n",
      "True variance: 2500\n",
      "\n",
      "Node 360:\n",
      "Predicted value: 50184.24953337631\n",
      "Predicted variance: 6539.318812274778\n",
      "True value: 50312.88471788069\n",
      "True variance: 2500\n",
      "\n",
      "Node 361:\n",
      "Predicted value: 50203.1821703639\n",
      "Predicted variance: 5388.305310343555\n",
      "True value: 50236.27196757137\n",
      "True variance: 2500\n",
      "\n",
      "Node 362:\n",
      "Predicted value: 50203.4021543884\n",
      "Predicted variance: 3740.533356893623\n",
      "True value: 50054.50805191468\n",
      "True variance: 2500\n",
      "\n",
      "Node 363:\n",
      "Predicted value: 50205.27234416079\n",
      "Predicted variance: 3703.6434062299218\n",
      "True value: 50176.5090836914\n",
      "True variance: 2500\n",
      "\n",
      "Node 364:\n",
      "Predicted value: 50097.01035300113\n",
      "Predicted variance: 4629.245139202112\n",
      "True value: 50163.86449032387\n",
      "True variance: 2500\n",
      "\n",
      "Node 365:\n",
      "Predicted value: 50228.777288032456\n",
      "Predicted variance: 4005.42213839856\n",
      "True value: 50279.61292966208\n",
      "True variance: 2500\n",
      "\n",
      "Node 366:\n",
      "Predicted value: 50238.81623275922\n",
      "Predicted variance: 4369.447733508019\n",
      "True value: 50192.74913367245\n",
      "True variance: 2500\n",
      "\n",
      "Node 367:\n",
      "Predicted value: 50182.084212130474\n",
      "Predicted variance: 4515.6433656883155\n",
      "True value: 49862.76066434711\n",
      "True variance: 2500\n",
      "\n",
      "Node 368:\n",
      "Predicted value: 50170.49656927128\n",
      "Predicted variance: 4679.761021610319\n",
      "True value: 50041.24756257091\n",
      "True variance: 2500\n",
      "\n",
      "Node 369:\n",
      "Predicted value: 50215.733722255085\n",
      "Predicted variance: 5637.227162698277\n",
      "True value: 50153.31867544045\n",
      "True variance: 2500\n",
      "\n",
      "Node 370:\n",
      "Predicted value: 50176.36878306126\n",
      "Predicted variance: 6624.339778454309\n",
      "True value: 50392.32143611386\n",
      "True variance: 2500\n",
      "\n",
      "Node 371:\n",
      "Predicted value: 50167.67031617427\n",
      "Predicted variance: 6401.706815400165\n",
      "True value: 50256.231250392724\n",
      "True variance: 2500\n",
      "\n",
      "Node 372:\n",
      "Predicted value: 50179.17044388271\n",
      "Predicted variance: 6003.035930455644\n",
      "True value: 50482.3686508436\n",
      "True variance: 2500\n",
      "\n",
      "Node 373:\n",
      "Predicted value: 50204.43267463335\n",
      "Predicted variance: 5437.64843725769\n",
      "True value: 50353.394936714656\n",
      "True variance: 2500\n",
      "\n",
      "Node 374:\n",
      "Predicted value: 50210.418366927035\n",
      "Predicted variance: 5172.497973433894\n",
      "True value: 50196.50030255539\n",
      "True variance: 2500\n",
      "\n",
      "Node 375:\n",
      "Predicted value: 50180.88760811223\n",
      "Predicted variance: 5131.650059513569\n",
      "True value: 50161.59604450328\n",
      "True variance: 2500\n",
      "\n",
      "Node 376:\n",
      "Predicted value: 50117.42729576229\n",
      "Predicted variance: 5064.103879794956\n",
      "True value: 50092.532800306\n",
      "True variance: 2500\n",
      "\n",
      "Node 377:\n",
      "Predicted value: 50047.2488983038\n",
      "Predicted variance: 2684.976553865546\n",
      "True value: 49975.05834291286\n",
      "True variance: 2500\n",
      "\n",
      "Node 378:\n",
      "Predicted value: 50261.87143745673\n",
      "Predicted variance: 2275.0489331026592\n",
      "True value: 50373.87667576836\n",
      "True variance: 2500\n",
      "\n",
      "Node 379:\n",
      "Predicted value: 50318.18764458629\n",
      "Predicted variance: 5198.616673839211\n",
      "True value: 49989.04255920038\n",
      "True variance: 2500\n",
      "\n",
      "Node 380:\n",
      "Predicted value: 50238.709366595176\n",
      "Predicted variance: 6904.621030241578\n",
      "True value: 49898.003941249604\n",
      "True variance: 2500\n",
      "\n",
      "Node 381:\n",
      "Predicted value: 50140.85438438587\n",
      "Predicted variance: 6395.159302644068\n",
      "True value: 49653.570565624825\n",
      "True variance: 2500\n",
      "\n",
      "Node 382:\n",
      "Predicted value: 50180.949504764285\n",
      "Predicted variance: 4003.126985162382\n",
      "True value: 49592.56322070057\n",
      "True variance: 2500\n",
      "\n",
      "Node 383:\n",
      "Predicted value: 50169.21142182474\n",
      "Predicted variance: 6851.752745007649\n",
      "True value: 50119.62019280139\n",
      "True variance: 2500\n",
      "\n",
      "Node 384:\n",
      "Predicted value: 50186.04551960133\n",
      "Predicted variance: 5916.244176723288\n",
      "True value: 50240.00311603785\n",
      "True variance: 2500\n",
      "\n",
      "Node 385:\n",
      "Predicted value: 50172.31654156797\n",
      "Predicted variance: 5231.831579039407\n",
      "True value: 49835.60909602063\n",
      "True variance: 2500\n",
      "\n",
      "Node 386:\n",
      "Predicted value: 50119.01516605496\n",
      "Predicted variance: 5118.896059421767\n",
      "True value: 49971.352263561064\n",
      "True variance: 2500\n",
      "\n",
      "Node 387:\n",
      "Predicted value: 50031.1123467104\n",
      "Predicted variance: 4962.9712152985\n",
      "True value: 49764.72468750011\n",
      "True variance: 2500\n",
      "\n",
      "Node 388:\n",
      "Predicted value: 49832.008149214074\n",
      "Predicted variance: 4627.042508635582\n",
      "True value: 49918.30912202041\n",
      "True variance: 2500\n",
      "\n",
      "Node 389:\n",
      "Predicted value: 49988.338380146924\n",
      "Predicted variance: 4703.267712573383\n",
      "True value: 50519.95922386859\n",
      "True variance: 2500\n",
      "\n",
      "Node 390:\n",
      "Predicted value: 49901.36207860725\n",
      "Predicted variance: 5072.70148808836\n",
      "True value: 50341.0105868979\n",
      "True variance: 2500\n",
      "\n",
      "Node 391:\n",
      "Predicted value: 49966.84079780763\n",
      "Predicted variance: 4051.134887844691\n",
      "True value: 50555.61076638577\n",
      "True variance: 2500\n",
      "\n",
      "Node 392:\n",
      "Predicted value: 49972.542930971904\n",
      "Predicted variance: 3970.046387961421\n",
      "True value: 50511.947214404725\n",
      "True variance: 2500\n",
      "\n",
      "Node 393:\n",
      "Predicted value: 49980.21979986378\n",
      "Predicted variance: 4193.787991729638\n",
      "True value: 50011.856498391004\n",
      "True variance: 2500\n",
      "\n",
      "Node 394:\n",
      "Predicted value: 50195.115940336516\n",
      "Predicted variance: 5520.304255076242\n",
      "True value: 49924.34104646653\n",
      "True variance: 2500\n",
      "\n",
      "Node 395:\n",
      "Predicted value: 50248.83528995448\n",
      "Predicted variance: 7238.197262756595\n",
      "True value: 50033.427037439236\n",
      "True variance: 2500\n",
      "\n",
      "Node 396:\n",
      "Predicted value: 50006.46593696473\n",
      "Predicted variance: 6318.560187955237\n",
      "True value: 50866.49660162096\n",
      "True variance: 2500\n",
      "\n",
      "Node 397:\n",
      "Predicted value: 50434.47943816871\n",
      "Predicted variance: 8190.671456243523\n",
      "True value: 50582.65702847306\n",
      "True variance: 2500\n",
      "\n",
      "Node 398:\n",
      "Predicted value: 50440.37592168129\n",
      "Predicted variance: 6312.875637405822\n",
      "True value: 50415.756044433234\n",
      "True variance: 2500\n",
      "\n",
      "Node 399:\n",
      "Predicted value: 50462.28511119228\n",
      "Predicted variance: 4475.119461604803\n",
      "True value: 50255.88994431738\n",
      "True variance: 2500\n",
      "\n",
      "Node 400:\n",
      "Predicted value: 50473.60643006378\n",
      "Predicted variance: 2934.412219350169\n",
      "True value: 50650.014136260535\n",
      "True variance: 2500\n",
      "\n",
      "Node 401:\n",
      "Predicted value: 50469.84626576825\n",
      "Predicted variance: 2858.8078816785487\n",
      "True value: 50376.62828634643\n",
      "True variance: 2500\n",
      "\n",
      "Node 402:\n",
      "Predicted value: 50472.515429814346\n",
      "Predicted variance: 2930.834699189379\n",
      "True value: 50564.9836788649\n",
      "True variance: 2500\n",
      "\n",
      "Node 403:\n",
      "Predicted value: 50474.27568332099\n",
      "Predicted variance: 3936.161712375392\n",
      "True value: 50724.2377950089\n",
      "True variance: 2500\n",
      "\n",
      "Node 404:\n",
      "Predicted value: 50517.42101173718\n",
      "Predicted variance: 3466.5713817118244\n",
      "True value: 50534.29307217533\n",
      "True variance: 2500\n",
      "\n",
      "Node 405:\n",
      "Predicted value: 50513.53614110847\n",
      "Predicted variance: 3485.8027393580683\n",
      "True value: 50273.54168958653\n",
      "True variance: 2500\n",
      "\n",
      "Node 406:\n",
      "Predicted value: 50436.72209412136\n",
      "Predicted variance: 4191.610331774943\n",
      "True value: 50363.373453154454\n",
      "True variance: 2500\n",
      "\n",
      "Node 407:\n",
      "Predicted value: 50318.40980554985\n",
      "Predicted variance: 1960.2029665212171\n",
      "True value: 50318.09319020433\n",
      "True variance: 2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def information_to_standard(clique_j, clique_h):\n",
    "\n",
    "    z_hats = np.zeros_like(clique_h)\n",
    "    z_vars = np.zeros_like(clique_h)\n",
    "\n",
    "    for i in range(len(clique_j)):\n",
    "        z_hats[i] = clique_h[i] / clique_j[i]\n",
    "        z_vars[i] = 1 / clique_j[i]\n",
    "\n",
    "    return z_hats, z_vars\n",
    "\n",
    "\n",
    "def J_msg(clique_tree, i, j, J, h, J_messages, h_messages, sent):\n",
    "    neighbors = list(clique_tree.neighbors(i))\n",
    "    neighbors.remove(j)\n",
    "\n",
    "    i_idx = mapping_GTM(i)\n",
    "    j_idx = mapping_GTM(j)\n",
    "\n",
    "    if not neighbors:\n",
    "        # Leaf node ‚Äî base case\n",
    "        J_messages[i_idx][j_idx] = -J[i_idx, j_idx] * J[j_idx, i_idx] / J[i_idx, i_idx]\n",
    "        sent[i_idx][j_idx] = True\n",
    "        return\n",
    "\n",
    "    # Collect required messages\n",
    "    incoming_msgs = [J_messages[mapping_GTM(k)][i_idx] for k in neighbors]\n",
    "\n",
    "    if any(np.isnan(m) for m in incoming_msgs):\n",
    "        print(\"Attempted to compute message with missing dependencies\")\n",
    "        return  # Dependencies not ready ‚Äî skip\n",
    "\n",
    "    J_sum = sum(incoming_msgs)\n",
    "    J_messages[i_idx][j_idx] = -J[i_idx, j_idx] * J[j_idx, i_idx] / (J[i_idx, i_idx] + J_sum)\n",
    "    sent[i_idx][j_idx] = True\n",
    "\n",
    "def h_msg(clique_tree, i, j, J, h, J_messages, h_messages, sent):\n",
    "    neighbors = list(clique_tree.neighbors(i))\n",
    "    neighbors.remove(j)\n",
    "\n",
    "    i_idx = mapping_GTM(i)\n",
    "    j_idx = mapping_GTM(j)\n",
    "\n",
    "    if not neighbors:\n",
    "        # Leaf node ‚Äî base case\n",
    "        h_messages[i_idx][j_idx] = -J[i_idx, j_idx] * h[i_idx] / J[i_idx, i_idx]\n",
    "        sent[i_idx][j_idx] = True\n",
    "        return\n",
    "\n",
    "    J_incoming = [J_messages[mapping_GTM(k)][i_idx] for k in neighbors]\n",
    "    h_incoming = [h_messages[mapping_GTM(k)][i_idx] for k in neighbors]\n",
    "\n",
    "    if any(np.isnan(x) for x in J_incoming + h_incoming):\n",
    "        print(\"Attempted to compute message with missing dependencies\")\n",
    "        return  # Dependencies not ready ‚Äî skip\n",
    "\n",
    "    J_sum = sum(J_incoming)\n",
    "    h_sum = sum(h_incoming)\n",
    "\n",
    "    Ji_backslash_j = J[i_idx, i_idx] + J_sum\n",
    "    hi_backslash_j = h[i_idx] + h_sum\n",
    "\n",
    "    h_messages[i_idx][j_idx] = -J[j_idx, i_idx] * hi_backslash_j / Ji_backslash_j\n",
    "    sent[i_idx][j_idx] = True\n",
    "\n",
    "def upward_pass(clique_tree, J, h, J_messages, h_messages, sent):\n",
    "    queue = deque()\n",
    "\n",
    "    # Start from leaves (nodes with degree 1)\n",
    "    leaves = [node for node in clique_tree.nodes if clique_tree.degree[node] == 1]\n",
    "    for leaf in leaves:\n",
    "        queue.append(leaf)\n",
    "\n",
    "    while queue:\n",
    "        current = queue.popleft()\n",
    "        for neighbor in clique_tree.neighbors(current):\n",
    "            i = current\n",
    "            j = neighbor\n",
    "            i_idx = mapping_GTM(i)\n",
    "            j_idx = mapping_GTM(j)\n",
    "\n",
    "            if not sent[i_idx][j_idx]:\n",
    "                # Check if all incoming messages to i (except from j) are ready\n",
    "                deps_ready = all(\n",
    "                    sent[mapping_GTM(k)][i_idx]\n",
    "                    for k in clique_tree.neighbors(i) if k != j\n",
    "                )\n",
    "                if deps_ready:\n",
    "                    J_msg(clique_tree, i, j, J, h, J_messages, h_messages, sent)\n",
    "                    h_msg(clique_tree, i, j, J, h, J_messages, h_messages, sent)\n",
    "                    queue.append(j)\n",
    "\n",
    "    return J_messages, h_messages\n",
    "\n",
    "def downward_pass(clique_tree, J, h, J_messages, h_messages, sent, root):\n",
    "    queue = deque([root])\n",
    "\n",
    "    while queue:\n",
    "        current = queue.popleft()\n",
    "        for neighbor in clique_tree.neighbors(current):\n",
    "            i = current\n",
    "            j = neighbor\n",
    "            i_idx = mapping_GTM(i)\n",
    "            j_idx = mapping_GTM(j)\n",
    "\n",
    "            if not sent[i_idx][j_idx]:\n",
    "                deps_ready = all(\n",
    "                    sent[mapping_GTM(k)][i_idx]\n",
    "                    for k in clique_tree.neighbors(i) if k != j\n",
    "                )\n",
    "                if deps_ready:\n",
    "                    J_msg(clique_tree, i, j, J, h, J_messages, h_messages, sent)\n",
    "                    h_msg(clique_tree, i, j, J, h, J_messages, h_messages, sent)\n",
    "                    queue.append(j)\n",
    "\n",
    "    return J_messages, h_messages\n",
    "\n",
    "def compute_clique_beliefs(clique_tree, J, h, J_messages, h_messages):\n",
    "    \n",
    "    clique_j = np.zeros(shape=h.shape)\n",
    "    clique_h = np.zeros(shape=h.shape)\n",
    "    \n",
    "    number_of_variables = len(h)\n",
    "    for i in range(number_of_variables):\n",
    "        J_i = J[i][i]\n",
    "        h_i = h[i]\n",
    "\n",
    "        graph_i = mapping_MTG(i)\n",
    "\n",
    "        for neighbor in clique_tree.neighbors(graph_i):\n",
    "            J_message = J_messages[mapping_GTM(neighbor)][i]\n",
    "            h_message = h_messages[mapping_GTM(neighbor)][i]\n",
    "            J_i += J_message\n",
    "            h_i += h_message\n",
    "        \n",
    "        clique_j[i] = J_i\n",
    "        clique_h[i] = h_i\n",
    "\n",
    "    return clique_j, clique_h\n",
    "\n",
    "def message_passing(G, alpha, beta, sigma_sq, alpha_0, sigma_0_sq, X_indices, observed_X):\n",
    "\n",
    "    single_clique_tree = single_clique(G)\n",
    "    J, h = compute_J_and_h(G, alpha, beta, sigma_sq, sigma_0_sq, alpha_0)\n",
    "\n",
    "    J_reduced, h_reduced, Z_nodes = get_conditional_distribution(J, h, observed_X, X_indices)\n",
    "\n",
    "        # Define full set of observed leaves (e.g., leaf nodes in G)\n",
    "    expected_X_indices = set([node for node in G.nodes if G.out_degree(node) == 0])\n",
    "\n",
    "    # Identify X variables that were not conditioned on (i.e. remain latent)\n",
    "    remaining_x = [node for node in expected_X_indices if node not in X_indices and node in Z_nodes]\n",
    "\n",
    "    if remaining_x:\n",
    "        print(\"Marginalizing out remaining Xs:\", remaining_x)\n",
    "        J_reduced, h_reduced = marginalize_out(J_reduced, h_reduced, remaining_x)\n",
    "        Z_nodes = [z for z in Z_nodes if z not in remaining_x]\n",
    "\n",
    "\n",
    "    J_messages = np.full(J_reduced.shape, np.nan)\n",
    "    h_messages = np.full(J_reduced.shape, np.nan)\n",
    "\n",
    "    sent = np.zeros_like(J_messages, dtype=bool)\n",
    "\n",
    "    J_msg_up, h_msg_up = upward_pass(single_clique_tree, J_reduced, h_reduced, J_messages, h_messages, sent)\n",
    "    J_msg_down, h_msg_down = downward_pass(single_clique_tree, J_reduced, h_reduced, J_msg_up, h_msg_up, sent, 407)\n",
    "    clique_j, clique_h = compute_clique_beliefs(single_clique_tree, J_reduced, h_reduced, J_msg_down, h_msg_down)\n",
    "    # print(\"Messages sent:\", np.sum(sent), \"/\", sent.size)\n",
    "\n",
    "    z_hats, z_vars = information_to_standard(clique_j, clique_h)\n",
    "    return z_hats, z_vars, Z_nodes\n",
    "\n",
    "alpha_0 = 50000\n",
    "sigma_0_sq = 5000\n",
    "z_hats, z_vars, Z_nodes = message_passing(G, alpha, beta, sigma_sq, alpha_0, sigma_0_sq, X_indices, X_values[0])\n",
    "\n",
    "\n",
    "prnt = True\n",
    "if prnt:\n",
    "    print(\"Maximum value: \", np.max(z_hats))\n",
    "    print(\"Minimum value: \", np.min(z_hats))\n",
    "\n",
    "    for i in range(len(z_hats)):\n",
    "        print(f\"Node {mapping_MTG(i)}:\")\n",
    "        print(f\"Predicted value: {z_hats[i]}\")\n",
    "        print(f\"Predicted variance: {z_vars[i]}\")\n",
    "        print(f\"True value: {X_values[0][i]}\")\n",
    "        print(f\"True variance: {sigma_sq}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III: Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1522,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated alpha: 0.5383219520569341\n",
      "Estimated beta: 1.0000120725506114\n",
      "Estimated sigma_sq: 2500.500251292229\n"
     ]
    }
   ],
   "source": [
    "def simulate_full_data(G, n_samples, alpha, beta, sigma_sq, alpha_0, sigma_0_sq):\n",
    "    rows = []\n",
    "\n",
    "    for _ in range(n_samples):\n",
    "        simulated = {}\n",
    "        simulated[root] = np.random.normal(alpha_0, np.sqrt(sigma_0_sq))\n",
    "        simulate_node_length_with_parameters(G, root, simulated, alpha, beta, sigma_sq)\n",
    "\n",
    "        for parent, child in G.edges:\n",
    "            t = G[parent][child]['time']\n",
    "            y = simulated[child]\n",
    "            z = simulated[parent]\n",
    "            rows.append({\n",
    "                'Y': y,\n",
    "                'Z': z,\n",
    "                't': t\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def estimate_alpha_beta_sigma2(data):\n",
    "    X = data[['t', 'Z']]\n",
    "    y = data['Y']\n",
    "\n",
    "    weights = 1 / data['t']\n",
    "    model = LinearRegression().fit(X, y, sample_weight=weights)\n",
    "    alpha_hat = model.coef_[0]\n",
    "    beta_hat = model.coef_[1]\n",
    "\n",
    "    # Residual variance estimate of œÉ¬≤\n",
    "\n",
    "    residuals = y - model.predict(X)\n",
    "    sigma_sq_hat = np.sum(weights * residuals**2) / len(y)\n",
    "\n",
    "    return alpha_hat, beta_hat, sigma_sq_hat\n",
    "\n",
    "root = 407\n",
    "n = 1000\n",
    "df = simulate_full_data(G, n, alpha=0.5, beta=1, sigma_sq=2500, alpha_0=50000, sigma_0_sq=5000)\n",
    "alpha_hat, beta_hat, sigma_sq_hat = estimate_alpha_beta_sigma2(df)\n",
    "\n",
    "print(\"Estimated alpha:\", alpha_hat)\n",
    "print(\"Estimated beta:\", beta_hat)\n",
    "print(\"Estimated sigma_sq:\", sigma_sq_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1523,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "--- Iteration 1 of 1 ---\n",
      "alpha: 1.6401157269670499\n",
      "beta: 0.038300673818972696\n",
      "sigma_sq: 19818.850146779627\n",
      "alpha_0: 49746.422636089235\n",
      "log-likelihood: -2388171.7008308694\n"
     ]
    }
   ],
   "source": [
    "def hard_assignment_EM(xs_lst, G, root, n_iter, alpha_init, beta_init, alpha0_init, sigma_sq_init, sigma_0_sq, trace = False):\n",
    "    \"\"\"\n",
    "    xs_lst: list of dictionaries, each with observed values (t and Y) for a given sample\n",
    "    G: DAG\n",
    "    root: root node id (e.g., 407)\n",
    "    n_iter: number of EM iterations\n",
    "    alpha_init, beta_init, alpha0_init, sigma_sq_init: initial parameter values\n",
    "    sigma_0_sq: fixed variance of the root prior\n",
    "    \"\"\"\n",
    "    alpha = alpha_init\n",
    "    beta = beta_init\n",
    "    sigma_sq = sigma_sq_init\n",
    "    alpha_0 = alpha0_init\n",
    "    log_likelihoods = []\n",
    "\n",
    "    for iter_num in range(n_iter):\n",
    "        zs_list = []\n",
    "\n",
    "        # -------- E-step: infer latent variables using message passing --------\n",
    "        for x_dict in xs_lst:\n",
    "            X_indices = list(x_dict.keys())\n",
    "            X_values = np.array(list(x_dict.values()))\n",
    "\n",
    "            z_hats, _, Z_nodes = message_passing(G, alpha, beta, sigma_sq, alpha_0, sigma_0_sq, X_indices, X_values)\n",
    "\n",
    "            inferred = {}\n",
    "            for node in G.nodes:\n",
    "                if node in X_indices:\n",
    "                    inferred[node] = x_dict[node]\n",
    "                elif node in Z_nodes:\n",
    "                    index = Z_nodes.index(node)\n",
    "                    inferred[node] = z_hats[index]\n",
    "\n",
    "            zs_list.append(inferred)\n",
    "\n",
    "        # -------- M-step: re-estimate parameters from (Y, Z, t) triplets --------\n",
    "        rows = []\n",
    "        for x, z in zip(xs_lst, zs_list):\n",
    "            for parent, child in G.edges:\n",
    "                if child in x:\n",
    "                    y = x[child]\n",
    "                    z_parent = z[parent]\n",
    "                    t = G[parent][child]['time']\n",
    "                    rows.append({'Y': y, 'Z': z_parent, 't': t})\n",
    "\n",
    "        df = pd.DataFrame(rows)\n",
    "        alpha, beta, sigma_sq = estimate_alpha_beta_sigma2(df)\n",
    "        alpha_0 = np.mean([z[mapping_GTM(root)] for z in zs_list])\n",
    "\n",
    "        # -------- Log-likelihood (data only) --------\n",
    "        if trace:\n",
    "            log_likelihood = 0.0\n",
    "            for row in rows:\n",
    "                y = row['Y']\n",
    "                z = row['Z']\n",
    "                t = row['t']\n",
    "                mean = alpha * t + beta * z\n",
    "                var = sigma_sq * t\n",
    "                ll = -0.5 * np.log(2 * np.pi * var) - 0.5 * ((y - mean) ** 2) / var\n",
    "                log_likelihood += ll\n",
    "\n",
    "            log_likelihoods.append(log_likelihood)\n",
    "\n",
    "            print(f\"--- Iteration {iter_num + 1} of {n_iter} ---\")\n",
    "            print(\"alpha:\", alpha)\n",
    "            print(\"beta:\", beta)\n",
    "            print(\"sigma_sq:\", sigma_sq)\n",
    "            print(\"alpha_0:\", alpha_0)\n",
    "            print(\"log-likelihood:\", log_likelihood)\n",
    "\n",
    "    return alpha, beta, sigma_sq, alpha_0, log_likelihoods\n",
    "\n",
    "\n",
    "\n",
    "def make_partial_observations(G, simulated_full):\n",
    "    leaves = [node for node in G.nodes if G.out_degree(node) == 0]\n",
    "    partial_data = []\n",
    "\n",
    "    for sample in simulated_full:\n",
    "        partial = {leaf: sample[leaf] for leaf in leaves}\n",
    "        partial_data.append(partial)\n",
    "\n",
    "    return partial_data\n",
    "\n",
    "\n",
    "def simulate_full_dataset(G, n_samples, alpha, beta, sigma_sq, alpha_0, sigma_0_sq, root):\n",
    "    all_samples = []\n",
    "\n",
    "    for _ in range(n_samples):\n",
    "        sample = {}\n",
    "        sample[root] = np.random.normal(alpha_0, np.sqrt(sigma_0_sq))\n",
    "        simulate_node_length_with_parameters(G, root, sample, alpha, beta, sigma_sq)\n",
    "        all_samples.append(sample)\n",
    "\n",
    "    return all_samples\n",
    "\n",
    "\n",
    "true_alpha = 0.5\n",
    "true_beta = 1.0\n",
    "true_sigma_sq = 2500\n",
    "true_alpha_0 = 50000\n",
    "true_sigma_0_sq = 5000\n",
    "root = 407\n",
    "n_samples = 1\n",
    "\n",
    "# Simulate full data\n",
    "full_data = simulate_full_dataset(G, n_samples, true_alpha, true_beta, true_sigma_sq, true_alpha_0, true_sigma_0_sq, root)\n",
    "\n",
    "# Get partial observations (only leaf nodes)\n",
    "xs_lst = make_partial_observations(G, full_data)\n",
    "\n",
    "alpha, beta, sigma_sq, alpha_0, log_likelihood = hard_assignment_EM(\n",
    "    xs_lst=xs_lst,\n",
    "    G=G,\n",
    "    root=407,\n",
    "    n_iter=1,\n",
    "    alpha_init=0,\n",
    "    beta_init=1.2,\n",
    "    alpha0_init=25000,\n",
    "    sigma_sq_init=1000,\n",
    "    sigma_0_sq=5000,\n",
    "    trace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part III: Apply inference and learning algorithms to real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1524,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orthId</th>\n",
       "      <th>glength_dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1CPN2</td>\n",
       "      <td>{1: 88338, 2: 219992, 3: 89972, 4: 233175, 5: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1CQBX</td>\n",
       "      <td>{1: 30935, 2: 31081, 3: 40971, 4: 32508, 5: 28...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1CQJ6</td>\n",
       "      <td>{1: 21555, 2: 20662, 3: 12707, 4: 21723, 5: 22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1CR8Z</td>\n",
       "      <td>{1: 12401, 2: 16419, 3: 11305, 4: 16328, 5: 59...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1CTEU</td>\n",
       "      <td>{1: 3125, 2: 2814, 3: 2122, 4: 2765, 5: 3457, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1CTI9</td>\n",
       "      <td>{1: 44314, 2: 42679, 3: 44077, 4: 36837, 5: 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1CYBB</td>\n",
       "      <td>{1: 104633, 2: 104930, 3: 105023, 4: 106842, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1D0EM</td>\n",
       "      <td>{1: 19977, 2: 21211, 3: 24187, 4: 22395, 5: 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1D1CF</td>\n",
       "      <td>{1: 16494, 2: 15176, 3: 16651, 4: 15010, 5: 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1D3F1</td>\n",
       "      <td>{1: 29924, 2: 8341, 3: 6260, 4: 9613, 5: 6236,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  orthId                                       glength_dict\n",
       "0  1CPN2  {1: 88338, 2: 219992, 3: 89972, 4: 233175, 5: ...\n",
       "1  1CQBX  {1: 30935, 2: 31081, 3: 40971, 4: 32508, 5: 28...\n",
       "2  1CQJ6  {1: 21555, 2: 20662, 3: 12707, 4: 21723, 5: 22...\n",
       "3  1CR8Z  {1: 12401, 2: 16419, 3: 11305, 4: 16328, 5: 59...\n",
       "4  1CTEU  {1: 3125, 2: 2814, 3: 2122, 4: 2765, 5: 3457, ...\n",
       "5  1CTI9  {1: 44314, 2: 42679, 3: 44077, 4: 36837, 5: 11...\n",
       "6  1CYBB  {1: 104633, 2: 104930, 3: 105023, 4: 106842, 5...\n",
       "7  1D0EM  {1: 19977, 2: 21211, 3: 24187, 4: 22395, 5: 21...\n",
       "8  1D1CF  {1: 16494, 2: 15176, 3: 16651, 4: 15010, 5: 16...\n",
       "9  1D3F1  {1: 29924, 2: 8341, 3: 6260, 4: 9613, 5: 6236,..."
      ]
     },
     "execution_count": 1524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_gene_data(tree, vert_genes):\n",
    "    data = pd.merge(tree, vert_genes, on='species', how='inner')\n",
    "    rows = []\n",
    "    for orth_id, group in data.groupby('orthId'):\n",
    "        child_glength = dict(zip(group['Child'], group['glength']))\n",
    "        rows.append({'orthId': orth_id, 'glength_dict': child_glength})\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "real_data = split_gene_data(tree, vert_genes)\n",
    "\n",
    "real_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observed values:  203\n",
      "J_ZX shape: (204, 203)\n",
      "X_values shape: (203,)\n",
      "Marginalizing out remaining Xs: [179]\n",
      "J_ZX shape: (204, 203)\n",
      "X_values shape: (203,)\n",
      "Marginalizing out remaining Xs: [179]\n",
      "J_ZX shape: (204, 203)\n",
      "X_values shape: (203,)\n",
      "Marginalizing out remaining Xs: [179]\n",
      "J_ZX shape: (204, 203)\n",
      "X_values shape: (203,)\n",
      "Marginalizing out remaining Xs: [179]\n",
      "J_ZX shape: (204, 203)\n",
      "X_values shape: (203,)\n",
      "Marginalizing out remaining Xs: [179]\n",
      "J_ZX shape: (204, 203)\n",
      "X_values shape: (203,)\n",
      "Marginalizing out remaining Xs: [179]\n",
      "J_ZX shape: (204, 203)\n",
      "X_values shape: (203,)\n",
      "Marginalizing out remaining Xs: [179]\n",
      "J_ZX shape: (204, 203)\n",
      "X_values shape: (203,)\n",
      "Marginalizing out remaining Xs: [179]\n",
      "J_ZX shape: (204, 203)\n",
      "X_values shape: (203,)\n",
      "Marginalizing out remaining Xs: [179]\n",
      "J_ZX shape: (204, 203)\n",
      "X_values shape: (203,)\n",
      "Marginalizing out remaining Xs: [179]\n",
      "Number of observed values:  204\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "Number of observed values:  202\n",
      "J_ZX shape: (205, 202)\n",
      "X_values shape: (202,)\n",
      "Marginalizing out remaining Xs: [90, 204]\n",
      "J_ZX shape: (205, 202)\n",
      "X_values shape: (202,)\n",
      "Marginalizing out remaining Xs: [90, 204]\n",
      "J_ZX shape: (205, 202)\n",
      "X_values shape: (202,)\n",
      "Marginalizing out remaining Xs: [90, 204]\n",
      "J_ZX shape: (205, 202)\n",
      "X_values shape: (202,)\n",
      "Marginalizing out remaining Xs: [90, 204]\n",
      "J_ZX shape: (205, 202)\n",
      "X_values shape: (202,)\n",
      "Marginalizing out remaining Xs: [90, 204]\n",
      "J_ZX shape: (205, 202)\n",
      "X_values shape: (202,)\n",
      "Marginalizing out remaining Xs: [90, 204]\n",
      "J_ZX shape: (205, 202)\n",
      "X_values shape: (202,)\n",
      "Marginalizing out remaining Xs: [90, 204]\n",
      "J_ZX shape: (205, 202)\n",
      "X_values shape: (202,)\n",
      "Marginalizing out remaining Xs: [90, 204]\n",
      "J_ZX shape: (205, 202)\n",
      "X_values shape: (202,)\n",
      "Marginalizing out remaining Xs: [90, 204]\n",
      "J_ZX shape: (205, 202)\n",
      "X_values shape: (202,)\n",
      "Marginalizing out remaining Xs: [90, 204]\n",
      "Number of observed values:  202\n",
      "J_ZX shape: (205, 202)\n",
      "X_values shape: (202,)\n",
      "Marginalizing out remaining Xs: [21, 105]\n",
      "J_ZX shape: (205, 202)\n",
      "X_values shape: (202,)\n",
      "Marginalizing out remaining Xs: [21, 105]\n",
      "J_ZX shape: (205, 202)\n",
      "X_values shape: (202,)\n",
      "Marginalizing out remaining Xs: [21, 105]\n",
      "J_ZX shape: (205, 202)\n",
      "X_values shape: (202,)\n",
      "Marginalizing out remaining Xs: [21, 105]\n",
      "J_ZX shape: (205, 202)\n",
      "X_values shape: (202,)\n",
      "Marginalizing out remaining Xs: [21, 105]\n",
      "J_ZX shape: (205, 202)\n",
      "X_values shape: (202,)\n",
      "Marginalizing out remaining Xs: [21, 105]\n",
      "J_ZX shape: (205, 202)\n",
      "X_values shape: (202,)\n",
      "Marginalizing out remaining Xs: [21, 105]\n",
      "J_ZX shape: (205, 202)\n",
      "X_values shape: (202,)\n",
      "Marginalizing out remaining Xs: [21, 105]\n",
      "J_ZX shape: (205, 202)\n",
      "X_values shape: (202,)\n",
      "Marginalizing out remaining Xs: [21, 105]\n",
      "J_ZX shape: (205, 202)\n",
      "X_values shape: (202,)\n",
      "Marginalizing out remaining Xs: [21, 105]\n",
      "Number of observed values:  204\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "Number of observed values:  204\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "Number of observed values:  204\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "Number of observed values:  188\n",
      "J_ZX shape: (219, 188)\n",
      "X_values shape: (188,)\n",
      "Marginalizing out remaining Xs: [20, 96, 109, 112, 113, 115, 150, 154, 160, 179, 189, 192, 193, 199, 203, 204]\n",
      "J_ZX shape: (219, 188)\n",
      "X_values shape: (188,)\n",
      "Marginalizing out remaining Xs: [20, 96, 109, 112, 113, 115, 150, 154, 160, 179, 189, 192, 193, 199, 203, 204]\n",
      "J_ZX shape: (219, 188)\n",
      "X_values shape: (188,)\n",
      "Marginalizing out remaining Xs: [20, 96, 109, 112, 113, 115, 150, 154, 160, 179, 189, 192, 193, 199, 203, 204]\n",
      "J_ZX shape: (219, 188)\n",
      "X_values shape: (188,)\n",
      "Marginalizing out remaining Xs: [20, 96, 109, 112, 113, 115, 150, 154, 160, 179, 189, 192, 193, 199, 203, 204]\n",
      "J_ZX shape: (219, 188)\n",
      "X_values shape: (188,)\n",
      "Marginalizing out remaining Xs: [20, 96, 109, 112, 113, 115, 150, 154, 160, 179, 189, 192, 193, 199, 203, 204]\n",
      "J_ZX shape: (219, 188)\n",
      "X_values shape: (188,)\n",
      "Marginalizing out remaining Xs: [20, 96, 109, 112, 113, 115, 150, 154, 160, 179, 189, 192, 193, 199, 203, 204]\n",
      "J_ZX shape: (219, 188)\n",
      "X_values shape: (188,)\n",
      "Marginalizing out remaining Xs: [20, 96, 109, 112, 113, 115, 150, 154, 160, 179, 189, 192, 193, 199, 203, 204]\n",
      "J_ZX shape: (219, 188)\n",
      "X_values shape: (188,)\n",
      "Marginalizing out remaining Xs: [20, 96, 109, 112, 113, 115, 150, 154, 160, 179, 189, 192, 193, 199, 203, 204]\n",
      "J_ZX shape: (219, 188)\n",
      "X_values shape: (188,)\n",
      "Marginalizing out remaining Xs: [20, 96, 109, 112, 113, 115, 150, 154, 160, 179, 189, 192, 193, 199, 203, 204]\n",
      "J_ZX shape: (219, 188)\n",
      "X_values shape: (188,)\n",
      "Marginalizing out remaining Xs: [20, 96, 109, 112, 113, 115, 150, 154, 160, 179, 189, 192, 193, 199, 203, 204]\n",
      "Number of observed values:  196\n",
      "J_ZX shape: (211, 196)\n",
      "X_values shape: (196,)\n",
      "Marginalizing out remaining Xs: [92, 102, 103, 110, 111, 155, 156, 157]\n",
      "J_ZX shape: (211, 196)\n",
      "X_values shape: (196,)\n",
      "Marginalizing out remaining Xs: [92, 102, 103, 110, 111, 155, 156, 157]\n",
      "J_ZX shape: (211, 196)\n",
      "X_values shape: (196,)\n",
      "Marginalizing out remaining Xs: [92, 102, 103, 110, 111, 155, 156, 157]\n",
      "J_ZX shape: (211, 196)\n",
      "X_values shape: (196,)\n",
      "Marginalizing out remaining Xs: [92, 102, 103, 110, 111, 155, 156, 157]\n",
      "J_ZX shape: (211, 196)\n",
      "X_values shape: (196,)\n",
      "Marginalizing out remaining Xs: [92, 102, 103, 110, 111, 155, 156, 157]\n",
      "J_ZX shape: (211, 196)\n",
      "X_values shape: (196,)\n",
      "Marginalizing out remaining Xs: [92, 102, 103, 110, 111, 155, 156, 157]\n",
      "J_ZX shape: (211, 196)\n",
      "X_values shape: (196,)\n",
      "Marginalizing out remaining Xs: [92, 102, 103, 110, 111, 155, 156, 157]\n",
      "J_ZX shape: (211, 196)\n",
      "X_values shape: (196,)\n",
      "Marginalizing out remaining Xs: [92, 102, 103, 110, 111, 155, 156, 157]\n",
      "J_ZX shape: (211, 196)\n",
      "X_values shape: (196,)\n",
      "Marginalizing out remaining Xs: [92, 102, 103, 110, 111, 155, 156, 157]\n",
      "J_ZX shape: (211, 196)\n",
      "X_values shape: (196,)\n",
      "Marginalizing out remaining Xs: [92, 102, 103, 110, 111, 155, 156, 157]\n",
      "Number of observed values:  201\n",
      "J_ZX shape: (206, 201)\n",
      "X_values shape: (201,)\n",
      "Marginalizing out remaining Xs: [98, 118, 132]\n",
      "J_ZX shape: (206, 201)\n",
      "X_values shape: (201,)\n",
      "Marginalizing out remaining Xs: [98, 118, 132]\n",
      "J_ZX shape: (206, 201)\n",
      "X_values shape: (201,)\n",
      "Marginalizing out remaining Xs: [98, 118, 132]\n",
      "J_ZX shape: (206, 201)\n",
      "X_values shape: (201,)\n",
      "Marginalizing out remaining Xs: [98, 118, 132]\n",
      "J_ZX shape: (206, 201)\n",
      "X_values shape: (201,)\n",
      "Marginalizing out remaining Xs: [98, 118, 132]\n",
      "J_ZX shape: (206, 201)\n",
      "X_values shape: (201,)\n",
      "Marginalizing out remaining Xs: [98, 118, 132]\n",
      "J_ZX shape: (206, 201)\n",
      "X_values shape: (201,)\n",
      "Marginalizing out remaining Xs: [98, 118, 132]\n",
      "J_ZX shape: (206, 201)\n",
      "X_values shape: (201,)\n",
      "Marginalizing out remaining Xs: [98, 118, 132]\n",
      "J_ZX shape: (206, 201)\n",
      "X_values shape: (201,)\n",
      "Marginalizing out remaining Xs: [98, 118, 132]\n",
      "J_ZX shape: (206, 201)\n",
      "X_values shape: (201,)\n",
      "Marginalizing out remaining Xs: [98, 118, 132]\n",
      "  orthId       alpha      beta      sigma_sq  alpha_0\n",
      "0  1CPN2   -3.191917  0.916683  1.470034e+09   4568.0\n",
      "1  1CQBX  -25.881673  0.939927  2.419881e+07  34954.0\n",
      "2  1CQJ6 -270.617179  0.632702  4.213799e+07   8561.0\n",
      "3  1CR8Z -196.813067  0.107123  5.150568e+06   6660.0\n",
      "4  1CTEU   63.244085  0.490900  3.467931e+06   2112.0\n",
      "5  1CTI9  -30.622432  0.938981  9.745271e+06  23791.0\n",
      "6  1CYBB -123.339124  0.914371  1.106389e+08  15853.0\n",
      "7  1D0EM  -57.445028  0.430715  1.014987e+07   3964.0\n",
      "8  1D1CF  103.284832  0.112502  3.320931e+07   7387.0\n",
      "9  1D3F1  -32.294367  0.582697  3.254076e+06   1881.0\n"
     ]
    }
   ],
   "source": [
    "def estimate_parameters_for_real_data(real_data, n_iter, alpha_init, beta_init, alpha0_init, sigma_sq_init, sigma_0_sq, root):\n",
    "    results = []\n",
    "\n",
    "    for _, row in real_data.iterrows():\n",
    "        orth_id = row['orthId']\n",
    "        glength_dict = row['glength_dict']\n",
    "\n",
    "        # Extract observed values (X_values) and their indices (X_indices)\n",
    "        X_indices = sorted([i for i in glength_dict.keys()])\n",
    "        X_values = np.array([glength_dict[i] for i in X_indices])\n",
    "\n",
    "        print(\"Number of observed values: \", len(X_values))\n",
    "\n",
    "        # Apply the EM algorithm to estimate parameters\n",
    "        alpha, beta, sigma_sq, alpha_0, _ = hard_assignment_EM(\n",
    "            xs_lst=[{idx: val for idx, val in zip(X_indices, X_values)}],\n",
    "            G=G,\n",
    "            root=root,\n",
    "            n_iter=n_iter,\n",
    "            alpha_init=alpha_init,\n",
    "            beta_init=beta_init,\n",
    "            alpha0_init=alpha0_init,\n",
    "            sigma_sq_init=sigma_sq_init,\n",
    "            sigma_0_sq=sigma_0_sq,\n",
    "            trace=False\n",
    "        )\n",
    "\n",
    "        # Store the results\n",
    "        results.append({\n",
    "            'orthId': orth_id,\n",
    "            'alpha': alpha,\n",
    "            'beta': beta,\n",
    "            'sigma_sq': sigma_sq,\n",
    "            'alpha_0': alpha_0\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Run the function on the real data\n",
    "estimated_parameters = estimate_parameters_for_real_data(\n",
    "    real_data=real_data,\n",
    "    n_iter=10,\n",
    "    alpha_init=0.5,\n",
    "    beta_init=1.0,\n",
    "    alpha0_init=50000,\n",
    "    sigma_sq_init=2500,\n",
    "    sigma_0_sq=5000,\n",
    "    root=407\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "print(estimated_parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1526,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orthId</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>sigma_sq</th>\n",
       "      <th>alpha_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1CPN2</td>\n",
       "      <td>-3.191917</td>\n",
       "      <td>0.916683</td>\n",
       "      <td>1.470034e+09</td>\n",
       "      <td>4568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1CQBX</td>\n",
       "      <td>-25.881673</td>\n",
       "      <td>0.939927</td>\n",
       "      <td>2.419881e+07</td>\n",
       "      <td>34954.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1CQJ6</td>\n",
       "      <td>-270.617179</td>\n",
       "      <td>0.632702</td>\n",
       "      <td>4.213799e+07</td>\n",
       "      <td>8561.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1CR8Z</td>\n",
       "      <td>-196.813067</td>\n",
       "      <td>0.107123</td>\n",
       "      <td>5.150568e+06</td>\n",
       "      <td>6660.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1CTEU</td>\n",
       "      <td>63.244085</td>\n",
       "      <td>0.490900</td>\n",
       "      <td>3.467931e+06</td>\n",
       "      <td>2112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1CTI9</td>\n",
       "      <td>-30.622432</td>\n",
       "      <td>0.938981</td>\n",
       "      <td>9.745271e+06</td>\n",
       "      <td>23791.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1CYBB</td>\n",
       "      <td>-123.339124</td>\n",
       "      <td>0.914371</td>\n",
       "      <td>1.106389e+08</td>\n",
       "      <td>15853.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1D0EM</td>\n",
       "      <td>-57.445028</td>\n",
       "      <td>0.430715</td>\n",
       "      <td>1.014987e+07</td>\n",
       "      <td>3964.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1D1CF</td>\n",
       "      <td>103.284832</td>\n",
       "      <td>0.112502</td>\n",
       "      <td>3.320931e+07</td>\n",
       "      <td>7387.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1D3F1</td>\n",
       "      <td>-32.294367</td>\n",
       "      <td>0.582697</td>\n",
       "      <td>3.254076e+06</td>\n",
       "      <td>1881.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  orthId       alpha      beta      sigma_sq  alpha_0\n",
       "0  1CPN2   -3.191917  0.916683  1.470034e+09   4568.0\n",
       "1  1CQBX  -25.881673  0.939927  2.419881e+07  34954.0\n",
       "2  1CQJ6 -270.617179  0.632702  4.213799e+07   8561.0\n",
       "3  1CR8Z -196.813067  0.107123  5.150568e+06   6660.0\n",
       "4  1CTEU   63.244085  0.490900  3.467931e+06   2112.0\n",
       "5  1CTI9  -30.622432  0.938981  9.745271e+06  23791.0\n",
       "6  1CYBB -123.339124  0.914371  1.106389e+08  15853.0\n",
       "7  1D0EM  -57.445028  0.430715  1.014987e+07   3964.0\n",
       "8  1D1CF  103.284832  0.112502  3.320931e+07   7387.0\n",
       "9  1D3F1  -32.294367  0.582697  3.254076e+06   1881.0"
      ]
     },
     "execution_count": 1526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimated_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1527,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J_ZX shape: (204, 203)\n",
      "X_values shape: (203,)\n",
      "size of J_reduced:  (204, 204)\n",
      "Ortholog ID: 1CPN2\n",
      "Posterior mean for root node: 30563.87502202885\n",
      "Posterior variance for root node: 4191.610331774942\n",
      "--------------------------------------------------\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "size of J_reduced:  (203, 203)\n",
      "Ortholog ID: 1CQBX\n",
      "Posterior mean for root node: 39982.716258990455\n",
      "Posterior variance for root node: 1960.203886744951\n",
      "--------------------------------------------------\n",
      "J_ZX shape: (205, 202)\n",
      "X_values shape: (202,)\n",
      "size of J_reduced:  (205, 205)\n",
      "Ortholog ID: 1CQJ6\n",
      "Posterior mean for root node: 8453.937725606373\n",
      "Posterior variance for root node: 3486.178264626228\n",
      "--------------------------------------------------\n",
      "J_ZX shape: (205, 202)\n",
      "X_values shape: (202,)\n",
      "size of J_reduced:  (205, 205)\n",
      "Ortholog ID: 1CR8Z\n",
      "Posterior mean for root node: 8619.928987713327\n",
      "Posterior variance for root node: 3485.8027393580705\n",
      "--------------------------------------------------\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "size of J_reduced:  (203, 203)\n",
      "Ortholog ID: 1CTEU\n",
      "Posterior mean for root node: 21205.099448828296\n",
      "Posterior variance for root node: 1960.203886744951\n",
      "--------------------------------------------------\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "size of J_reduced:  (203, 203)\n",
      "Ortholog ID: 1CTI9\n",
      "Posterior mean for root node: 34215.96355444862\n",
      "Posterior variance for root node: 1960.203886744951\n",
      "--------------------------------------------------\n",
      "J_ZX shape: (203, 204)\n",
      "X_values shape: (204,)\n",
      "size of J_reduced:  (203, 203)\n",
      "Ortholog ID: 1CYBB\n",
      "Posterior mean for root node: 31131.576971242022\n",
      "Posterior variance for root node: 1960.203886744951\n",
      "--------------------------------------------------\n",
      "J_ZX shape: (219, 188)\n",
      "X_values shape: (188,)\n",
      "size of J_reduced:  (219, 219)\n",
      "Ortholog ID: 1D0EM\n",
      "Posterior mean for root node: 7678.5871684581325\n",
      "Posterior variance for root node: 4123.131151348133\n",
      "--------------------------------------------------\n",
      "J_ZX shape: (211, 196)\n",
      "X_values shape: (196,)\n",
      "size of J_reduced:  (211, 211)\n",
      "Ortholog ID: 1D1CF\n",
      "Posterior mean for root node: 16763.92991765463\n",
      "Posterior variance for root node: 4475.119461604803\n",
      "--------------------------------------------------\n",
      "J_ZX shape: (206, 201)\n",
      "X_values shape: (201,)\n",
      "size of J_reduced:  (206, 206)\n",
      "Ortholog ID: 1D3F1\n",
      "Posterior mean for root node: 1630.0670764944246\n",
      "Posterior variance for root node: 3466.5713817118253\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each row in the real_data DataFrame\n",
    "for _, row in real_data.iterrows():\n",
    "    orth_id = row['orthId']\n",
    "    glength_dict = row['glength_dict']\n",
    "\n",
    "    # Extract observed values (X_values) and their indices (X_indices)\n",
    "    X_indices = list(glength_dict.keys())\n",
    "    X_values = np.array(list(glength_dict.values()))\n",
    "\n",
    "    # Compute the reduced precision matrix and potential vector\n",
    "    J_reduced, h_reduced, Z_nodes = get_conditional_distribution(J, h, X_values, X_indices)\n",
    "\n",
    "    print(\"size of J_reduced: \", J_reduced.shape)\n",
    "    # Compute the posterior covariance matrix (Sigma) and mean (mu)\n",
    "    Sigma = np.linalg.inv(J_reduced)\n",
    "    mu = Sigma @ h_reduced\n",
    "\n",
    "    # Map the root node index to the reduced matrix\n",
    "    root_index = mapping_GTM(root)\n",
    "\n",
    "    # Extract the posterior mean and variance for the root node\n",
    "    posterior_mean = mu[root_index]\n",
    "    posterior_variance = Sigma[root_index, root_index]\n",
    "\n",
    "    print(f\"Ortholog ID: {orth_id}\")\n",
    "    print(f\"Posterior mean for root node: {posterior_mean}\")\n",
    "    print(f\"Posterior variance for root node: {posterior_variance}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J_ZX shape: (204, 203)\n",
      "X_values shape: (203,)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'numpy.float64' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1528], line 29\u001b[0m\n\u001b[0;32m     25\u001b[0m             alpha_0[i] \u001b[38;5;241m=\u001b[39m alpha_0_hat\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m alpha, beta, sigma_sq, alpha_0\n\u001b[1;32m---> 29\u001b[0m alpha, beta, sigma_sq, alpha_0 \u001b[38;5;241m=\u001b[39m \u001b[43mhard_assignment_EM_real_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(real_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOrtholog ID:\u001b[39m\u001b[38;5;124m\"\u001b[39m, real_data\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morthId\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[1;32mIn[1528], line 17\u001b[0m, in \u001b[0;36mhard_assignment_EM_real_data\u001b[1;34m(real_data, n, alpha_init, beta_init, alpha0_init, sigma_sq_init, root)\u001b[0m\n\u001b[0;32m     14\u001b[0m X_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mlist\u001b[39m(glength_dict\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[0;32m     16\u001b[0m J_hat_z, h_hat_z \u001b[38;5;241m=\u001b[39m inference_algorithm(G, alpha[i], beta[i], sigma_sq[i], alpha_0[i], X_indices, X_values, root)\n\u001b[1;32m---> 17\u001b[0m alpha_0_hat, _ \u001b[38;5;241m=\u001b[39m \u001b[43minformation_to_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43mJ_hat_z\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_hat_z\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m df \u001b[38;5;241m=\u001b[39m simulate_full_data(G, \u001b[38;5;241m100\u001b[39m, alpha[i], beta[i], sigma_sq[i], alpha_0[i], \u001b[38;5;241m5000\u001b[39m)\n\u001b[0;32m     20\u001b[0m alpha_hat, beta_hat, sigma_sq_hat \u001b[38;5;241m=\u001b[39m estimate_alpha_beta_sigma2(df)\n",
      "Cell \u001b[1;32mIn[1521], line 6\u001b[0m, in \u001b[0;36minformation_to_standard\u001b[1;34m(clique_j, clique_h)\u001b[0m\n\u001b[0;32m      3\u001b[0m z_hats \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros_like(clique_h)\n\u001b[0;32m      4\u001b[0m z_vars \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros_like(clique_h)\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclique_j\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[0;32m      7\u001b[0m     z_hats[i] \u001b[38;5;241m=\u001b[39m clique_h[i] \u001b[38;5;241m/\u001b[39m clique_j[i]\n\u001b[0;32m      8\u001b[0m     z_vars[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m clique_j[i]\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'numpy.float64' has no len()"
     ]
    }
   ],
   "source": [
    "def hard_assignment_EM_real_data(real_data, n, alpha_init, beta_init, alpha0_init, sigma_sq_init, root = 407):\n",
    "    \n",
    "    for i in range(n):\n",
    "        alpha = np.array([alpha_init] * real_data.shape[0])\n",
    "        beta = np.array([beta_init] * real_data.shape[0])\n",
    "        sigma_sq = np.array([sigma_sq_init] * real_data.shape[0])\n",
    "        alpha_0 = np.array([alpha0_init] * real_data.shape[0])\n",
    "\n",
    "        for i, row in real_data.iterrows():\n",
    "            orth_id = row['orthId']\n",
    "            glength_dict = row['glength_dict']\n",
    "\n",
    "            X_indices = list(glength_dict.keys())\n",
    "            X_values = np.array(list(glength_dict.values()))\n",
    "\n",
    "            J_hat_z, h_hat_z = inference_algorithm(G, alpha[i], beta[i], sigma_sq[i], alpha_0[i], X_indices, X_values, root)\n",
    "            alpha_0_hat, _ = information_to_standard(J_hat_z, h_hat_z)\n",
    "\n",
    "            df = simulate_full_data(G, 100, alpha[i], beta[i], sigma_sq[i], alpha_0[i], 5000)\n",
    "            alpha_hat, beta_hat, sigma_sq_hat = estimate_alpha_beta_sigma2(df)\n",
    "\n",
    "            alpha[i] = alpha_hat\n",
    "            beta[i] = beta_hat\n",
    "            sigma_sq[i] = sigma_sq_hat\n",
    "            alpha_0[i] = alpha_0_hat\n",
    "\n",
    "    return alpha, beta, sigma_sq, alpha_0\n",
    "\n",
    "alpha, beta, sigma_sq, alpha_0 = hard_assignment_EM_real_data(real_data, 1, 0.5, 1, 50000, 5000)\n",
    "\n",
    "for i in range(real_data.shape[0]):\n",
    "    print(\"Ortholog ID:\", real_data.iloc[i]['orthId'])\n",
    "    print(\"Estimated alpha:\", alpha[i])\n",
    "    print(\"Estimated beta:\", beta[i])\n",
    "    print(\"Estimated sigma_sq:\", sigma_sq[i])\n",
    "    print(\"Estimated alpha_0:\", alpha_0[i])\n",
    "    print(\"-\" * 50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
